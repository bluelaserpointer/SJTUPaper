\contentsline {figure}{\numberline {2.1}{\ignorespaces 示例图来自~\blx@tocontentsinit {0}\cite {ozel_arkit_facs_cheatsheet}，展示 FACS AU45（blink）对应的 ARKit 中的两种 BlendShape 基形：\texttt {eyeBlinkLeft}（闭左眼）与 \texttt {eyeBlinkRight}（闭右眼）。}}{8}{figure.caption.21}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces BlendShape 线性插值效果示例：\texttt {eyeBlink} 从 $w{=}0$（左）到 $w{=}1$（右）的连续变化，中图为中间值。BS 权重可直接用于实时渲染驱动。}}{8}{figure.caption.22}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces MediaPipe Face Mesh 关键点结构示意图，截取自 \blx@tocontentsinit {0}\cite {mediapipefacemesh}。}}{9}{figure.caption.24}%
\contentsline {figure}{\numberline {3.1}{\ignorespaces 系统整体架构与数据流示意图}}{18}{figure.caption.30}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces 双向与单向 LSTM 对比示意图。 双向结构（上）在每个时间步同时利用历史与未来帧特征进行建模； 单向结构（下）仅基于历史帧进行递推，以保持因果性并支持流式推理。}}{24}{figure.caption.35}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces 滑动窗口训练机制：模型通过自回归循环预测 $M$ 帧，每步使用 $N$ 帧上下文并预测第 $N+1$ 帧。损失函数累计所有预测帧的误差，保证因果性与时间平滑性。}}{26}{figure.caption.36}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces 头部姿态编码器结构示意图。 输入为 Rot6d 表示的 6 维旋转向量，经两层前馈网络与 ReLU 非线性映射， 输出 12 维紧凑潜在表征。 该编码结果与语音、面部嵌入拼接后输入解码器，用于补充动作的方向与节奏信号。}}{27}{figure.caption.39}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces FaceCapGes 模型结构：音频、面部、头部编码器分别提取模态特征后拼接，输入至 LSTM 解码器生成躯干与手部动作，仅保留最后一帧输出作为当前时刻预测，符合帧级实时推理设定。训练阶段历史姿态序列比目标长度少一帧，需进行零填充。}}{28}{figure.caption.41}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces BEAT 数据集的骨架拓扑结构。 蓝色部分为 FaceCapGes 模型的控制区域， 涵盖上肢与三段脊椎关节，其余节点保持静态。 }}{29}{figure.caption.45}%
\contentsfinish 
\contentsfinish 
\contentsfinish 
\contentsfinish 
\contentsfinish 
\contentsfinish 

\relax 
\abx@aux@refcontext{none/global//global/global/global}
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/A>>}
\providecommand \oddpage@label [2]{}
\HyPL@Entry{6<</S/R>>}
\gdef \LT@i {\LT@entry 
    {1}{18.40791pt}\LT@entry 
    {1}{54.15749pt}}
\newlabel{chap:symb}{{}{XIII}{}{chapter*.14}{}}
\abx@aux@cite{0}{mediapipefacemesh}
\abx@aux@segm{0}{0}{mediapipefacemesh}
\abx@aux@cite{0}{AppleARKitTrackingGuide}
\abx@aux@segm{0}{0}{AppleARKitTrackingGuide}
\HyPL@Entry{20<</S/D>>}
\pp@pagectr{footnote}{1}{21}{1}
\@writefile{toc}{\contentsline {chapter}{\numberline {第 1 章}引言}{1}{chapter.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.1}研究背景和意义}{1}{section.1.1}\protected@file@percent }
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}研究内容}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}论文组织架构}{3}{section.1.3}\protected@file@percent }
\abx@aux@cite{0}{mcneill_1992_hand}
\abx@aux@segm{0}{0}{mcneill_1992_hand}
\abx@aux@cite{0}{kendon_2004_gesture}
\abx@aux@segm{0}{0}{kendon_2004_gesture}
\abx@aux@cite{0}{gesture_and_speech_in_interaction}
\abx@aux@segm{0}{0}{gesture_and_speech_in_interaction}
\pp@pagectr{footnote}{2}{25}{5}
\@writefile{toc}{\contentsline {chapter}{\numberline {第 2 章}相关工作}{5}{chapter.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.1}手势的定义与身体姿态的参数化表示}{5}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}手势的定义与范围}{5}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{手部手势的分类}{5}{paragraph*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{头部手势的分类}{5}{paragraph*.16}\protected@file@percent }
\abx@aux@cite{0}{busso2007rigidheadmotion}
\abx@aux@segm{0}{0}{busso2007rigidheadmotion}
\abx@aux@cite{0}{rot6d}
\abx@aux@segm{0}{0}{rot6d}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}身体姿态的参数化表示}{6}{subsection.2.1.2}\protected@file@percent }
\abx@aux@cite{0}{rot6d}
\abx@aux@segm{0}{0}{rot6d}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\abx@aux@cite{0}{diffsheg}
\abx@aux@segm{0}{0}{diffsheg}
\abx@aux@cite{0}{emage}
\abx@aux@segm{0}{0}{emage}
\abx@aux@cite{0}{ARKitDocumentation}
\abx@aux@segm{0}{0}{ARKitDocumentation}
\abx@aux@cite{0}{ozel_arkit_facs_cheatsheet}
\abx@aux@segm{0}{0}{ozel_arkit_facs_cheatsheet}
\abx@aux@cite{0}{ozel_arkit_facs_cheatsheet}
\abx@aux@segm{0}{0}{ozel_arkit_facs_cheatsheet}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces 不同旋转表示方式的空间连续性与使用示例}}{7}{table.caption.17}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rotation_comparison}{{2.1}{7}{不同旋转表示方式的空间连续性与使用示例}{table.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}面部表情的定义与参数化表示}{7}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{BlendShape 权重模型}{7}{paragraph*.18}\protected@file@percent }
\abx@aux@cite{0}{mediapipefacemesh}
\abx@aux@segm{0}{0}{mediapipefacemesh}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 示例图来自~\blx@tocontentsinit {0}\cite {ozel_arkit_facs_cheatsheet}，展示 FACS AU45（blink）对应的 ARKit 中的两种 BlendShape 基形：\texttt  {eyeBlinkLeft}（闭左眼）与 \texttt  {eyeBlinkRight}（闭右眼）。}}{8}{figure.caption.19}\protected@file@percent }
\newlabel{fig:au_sample}{{2.1}{8}{示例图来自~\cite {ozel_arkit_facs_cheatsheet}，展示 FACS AU45（blink）对应的 ARKit 中的两种 BlendShape 基形：\texttt {eyeBlinkLeft}（闭左眼）与 \texttt {eyeBlinkRight}（闭右眼）。}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces BlendShape 线性插值效果示例：\texttt  {eyeBlink} 从 $w{=}0$（左）到 $w{=}1$（右）的连续变化，中图为中间值。BS 权重可直接用于实时渲染驱动。}}{8}{figure.caption.20}\protected@file@percent }
\newlabel{fig:bs_eyeblink}{{2.2}{8}{BlendShape 线性插值效果示例：\texttt {eyeBlink} 从 $w{=}0$（左）到 $w{=}1$（右）的连续变化，中图为中间值。BS 权重可直接用于实时渲染驱动。}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {paragraph}{关键点坐标模型（Landmark-based Representation）}{8}{paragraph*.21}\protected@file@percent }
\abx@aux@cite{0}{mediapipefacemesh}
\abx@aux@segm{0}{0}{mediapipefacemesh}
\abx@aux@cite{0}{mediapipefacemesh}
\abx@aux@segm{0}{0}{mediapipefacemesh}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces MediaPipe Face Mesh 关键点结构示意图，截取自 \blx@tocontentsinit {0}\cite {mediapipefacemesh}。}}{9}{figure.caption.22}\protected@file@percent }
\newlabel{fig_mediapipe_landmark}{{2.3}{9}{MediaPipe Face Mesh 关键点结构示意图，截取自 \cite {mediapipefacemesh}。}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}国内外研究现状}{9}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}手势生成的研究目标}{9}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.1}研究目标类型的差异}{9}{subsubsection.2.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{为AI的虚拟形象生成手势}{9}{paragraph*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{为用户的虚拟人生成实时手势}{9}{paragraph*.24}\protected@file@percent }
\abx@aux@cite{0}{ginosar2019speech2gesture}
\abx@aux@segm{0}{0}{ginosar2019speech2gesture}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.2}任务约束与可利用条件的差异}{10}{subsubsection.2.3.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces 两类手势生成任务在约束与可利用条件上的对比}}{10}{table.caption.25}\protected@file@percent }
\newlabel{tab:task_constraint_comparison}{{2.2}{10}{两类手势生成任务在约束与可利用条件上的对比}{table.caption.25}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.3}评估方法}{10}{subsubsection.2.3.1.3}\protected@file@percent }
\abx@aux@cite{0}{kucherenko2021predictability}
\abx@aux@segm{0}{0}{kucherenko2021predictability}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\abx@aux@cite{0}{behavior_expression_animation_toolkit}
\abx@aux@segm{0}{0}{behavior_expression_animation_toolkit}
\abx@aux@cite{0}{robot_behavior_toolkit}
\abx@aux@segm{0}{0}{robot_behavior_toolkit}
\abx@aux@cite{0}{gesture_generation_by_imitation}
\abx@aux@segm{0}{0}{gesture_generation_by_imitation}
\abx@aux@cite{0}{gesture_and_speech_in_interaction}
\abx@aux@segm{0}{0}{gesture_and_speech_in_interaction}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}手势生成的演变}{11}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.1}规则驱动阶段}{11}{subsubsection.2.3.2.1}\protected@file@percent }
\abx@aux@cite{0}{rot6d}
\abx@aux@segm{0}{0}{rot6d}
\abx@aux@cite{0}{emage}
\abx@aux@segm{0}{0}{emage}
\abx@aux@cite{0}{AMUSE2024}
\abx@aux@segm{0}{0}{AMUSE2024}
\abx@aux@cite{0}{diffsheg}
\abx@aux@segm{0}{0}{diffsheg}
\abx@aux@cite{0}{emage}
\abx@aux@segm{0}{0}{emage}
\abx@aux@cite{0}{zhang2024SemanticGesticulator}
\abx@aux@segm{0}{0}{zhang2024SemanticGesticulator}
\abx@aux@cite{0}{tamingDiffgesture}
\abx@aux@segm{0}{0}{tamingDiffgesture}
\abx@aux@cite{0}{diffsheg}
\abx@aux@segm{0}{0}{diffsheg}
\abx@aux@cite{0}{diffstylegesture}
\abx@aux@segm{0}{0}{diffstylegesture}
\abx@aux@cite{0}{DiffTED2024}
\abx@aux@segm{0}{0}{DiffTED2024}
\abx@aux@cite{0}{diffusion-self-supervised2023}
\abx@aux@segm{0}{0}{diffusion-self-supervised2023}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\abx@aux@cite{0}{emage}
\abx@aux@segm{0}{0}{emage}
\abx@aux@cite{0}{diffsheg}
\abx@aux@segm{0}{0}{diffsheg}
\abx@aux@cite{0}{DiffTED2024}
\abx@aux@segm{0}{0}{DiffTED2024}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.2}数据驱动阶段}{12}{subsubsection.2.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.3}多模态扩展阶段}{12}{subsubsection.2.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}当代生成研究的策略趋势}{12}{subsection.2.3.3}\protected@file@percent }
\abx@aux@cite{0}{yoon2020speechgesturebert}
\abx@aux@segm{0}{0}{yoon2020speechgesturebert}
\abx@aux@cite{0}{alexanderson2023diffgesture}
\abx@aux@segm{0}{0}{alexanderson2023diffgesture}
\abx@aux@cite{0}{zhang2024SemanticGesticulator}
\abx@aux@segm{0}{0}{zhang2024SemanticGesticulator}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\abx@aux@cite{0}{alexanderson2023diffgesture}
\abx@aux@segm{0}{0}{alexanderson2023diffgesture}
\abx@aux@cite{0}{tamingDiffgesture}
\abx@aux@segm{0}{0}{tamingDiffgesture}
\abx@aux@cite{0}{diffsheg}
\abx@aux@segm{0}{0}{diffsheg}
\abx@aux@cite{0}{ginosar2019speech2gesture}
\abx@aux@segm{0}{0}{ginosar2019speech2gesture}
\abx@aux@cite{0}{alexanderson2020stylegestures}
\abx@aux@segm{0}{0}{alexanderson2020stylegestures}
\abx@aux@cite{0}{kucherenko2021movingfastslow}
\abx@aux@segm{0}{0}{kucherenko2021movingfastslow}
\abx@aux@cite{0}{kucherenko2021predictability}
\abx@aux@segm{0}{0}{kucherenko2021predictability}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}实时生成的理论基础与可行性分析}{13}{section.2.4}\protected@file@percent }
\abx@aux@cite{0}{kucherenko2021predictability}
\abx@aux@segm{0}{0}{kucherenko2021predictability}
\@writefile{toc}{\contentsline {paragraph}{头部姿态模态的建模意义}{14}{paragraph*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{头部模态补充语音驱动的空间指向性预测}{14}{paragraph*.27}\protected@file@percent }
\abx@aux@cite{0}{tamingDiffgesture}
\abx@aux@segm{0}{0}{tamingDiffgesture}
\abx@aux@cite{0}{diffsheg}
\abx@aux@segm{0}{0}{diffsheg}
\abx@aux@cite{0}{emage}
\abx@aux@segm{0}{0}{emage}
\abx@aux@cite{0}{DiffTED2024}
\abx@aux@segm{0}{0}{DiffTED2024}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}本文的工作与创新点}{15}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}本章小结}{15}{section.2.6}\protected@file@percent }
\pp@pagectr{footnote}{3}{37}{17}
\@writefile{toc}{\contentsline {chapter}{\numberline {第 3 章}方法}{17}{chapter.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.1}研究定位与总体设计思路}{17}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}系统整体框架与模块定位}{17}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{说话人配置选择.}{17}{paragraph*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{面部模态的外部传递.}{17}{paragraph*.30}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces 系统整体框架与数据流示意图}}{18}{figure.caption.28}\protected@file@percent }
\newlabel{fig:overallFramework}{{3.1}{18}{系统整体框架与数据流示意图}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}输入采集模块}{18}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}实时手势生成模块（FaceCapGes）}{19}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}渲染与驱动模块}{19}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}问题定义}{19}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}任务描述}{20}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}输入与输出模态}{20}{subsection.3.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces 输入输出模态符号与维度}}{20}{table.caption.31}\protected@file@percent }
\newlabel{tab:modalities}{{3.1}{20}{输入输出模态符号与维度}{table.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}学习目标与优化形式}{20}{subsection.3.3.3}\protected@file@percent }
\abx@aux@cite{0}{liu2022beat}
\abx@aux@segm{0}{0}{liu2022beat}
\abx@aux@cite{0}{mcneill1992hand}
\abx@aux@segm{0}{0}{mcneill1992hand}
\abx@aux@cite{0}{kendon2004gesture}
\abx@aux@segm{0}{0}{kendon2004gesture}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}级联架构与输入模态设计}{21}{section.3.4}\protected@file@percent }
\newlabel{sec:input_encoding}{{3.4}{21}{级联架构与输入模态设计}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}级联架构的原理与理论背景}{21}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}基线模态继承与实时适配}{21}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2.1}说话人 ID 分支移除.}{22}{subsubsection.3.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2.2}输入模态继承.}{22}{subsubsection.3.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2.3}输出模态继承（身体姿态解码）.}{22}{subsubsection.3.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2.4}时间建模结构改动与因果性约束.}{23}{subsubsection.3.4.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2.5}滑动窗口式自回归训练.}{23}{subsubsection.3.4.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces 双向与单向 LSTM 对比示意图。 双向结构（上）在每一时刻依赖未来帧，需整段输入； 单向结构（下）仅依赖历史帧，可逐步生成当前姿态。}}{24}{figure.caption.32}\protected@file@percent }
\newlabel{fig_lstmcompare}{{3.2}{24}{双向与单向 LSTM 对比示意图。 双向结构（上）在每一时刻依赖未来帧，需整段输入； 单向结构（下）仅依赖历史帧，可逐步生成当前姿态。}{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces 滑动窗口训练机制：模型通过自回归循环预测 $M$ 帧，每步使用 $N$ 帧上下文并预测第 $N+1$ 帧。损失函数累计所有预测帧的误差，保证因果性与时间平滑性。}}{25}{figure.caption.33}\protected@file@percent }
\newlabel{fig2_}{{3.3}{25}{滑动窗口训练机制：模型通过自回归循环预测 $M$ 帧，每步使用 $N$ 帧上下文并预测第 $N+1$ 帧。损失函数累计所有预测帧的误差，保证因果性与时间平滑性。}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}头部姿态模态的引入与结构位置}{25}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{输入特征与表示.}{26}{paragraph*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{编码器结构.}{26}{paragraph*.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces 头部姿态编码器结构示意图。 输入为 Rot6d 表示的 6 维旋转向量，经两层前馈网络与 ReLU 非线性映射， 输出 12 维紧凑潜在表征。 该编码结果与语音、面部嵌入拼接后输入解码器，用于补充动作的方向与节奏信号。}}{26}{figure.caption.36}\protected@file@percent }
\newlabel{fig_headencoder}{{3.4}{26}{头部姿态编码器结构示意图。 输入为 Rot6d 表示的 6 维旋转向量，经两层前馈网络与 ReLU 非线性映射， 输出 12 维紧凑潜在表征。 该编码结果与语音、面部嵌入拼接后输入解码器，用于补充动作的方向与节奏信号。}{figure.caption.36}{}}
\@writefile{toc}{\contentsline {paragraph}{架构位置与实验依据.}{26}{paragraph*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}小结：从语义驱动到反应调节的信号层级}{26}{subsection.3.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces FaceCapGes 模型结构：音频、面部、头部编码器分别提取模态特征后拼接，输入至 LSTM 解码器生成躯干与手部动作，仅保留最后一帧输出作为当前时刻预测，符合帧级实时推理设定。训练阶段历史姿态序列比目标长度少一帧，需进行零填充。}}{27}{figure.caption.38}\protected@file@percent }
\newlabel{fig1_}{{3.5}{27}{FaceCapGes 模型结构：音频、面部、头部编码器分别提取模态特征后拼接，输入至 LSTM 解码器生成躯干与手部动作，仅保留最后一帧输出作为当前时刻预测，符合帧级实时推理设定。训练阶段历史姿态序列比目标长度少一帧，需进行零填充。}{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}训练与损失函数设计}{27}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{手势重构损失.}{27}{paragraph*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{对抗损失.}{27}{paragraph*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总体损失.}{27}{paragraph*.41}\protected@file@percent }
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\abx@aux@cite{0}{adam2017}
\abx@aux@segm{0}{0}{adam2017}
\abx@aux@cite{0}{emage}
\abx@aux@segm{0}{0}{emage}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}实现与训练配置}{28}{section.3.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces  BEAT 数据集的骨架拓扑结构。 蓝色部分为 FaceCapGes 模型的控制区域， 涵盖上肢与三段脊椎关节，其余节点保持静态。 }}{28}{figure.caption.42}\protected@file@percent }
\newlabel{fig_beatbones}{{3.6}{28}{BEAT 数据集的骨架拓扑结构。 蓝色部分为 FaceCapGes 模型的控制区域， 涵盖上肢与三段脊椎关节，其余节点保持静态。}{figure.caption.42}{}}
\@writefile{toc}{\contentsline {paragraph}{训练配置.}{28}{paragraph*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{姿态表示.}{29}{paragraph*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{运行性能.}{29}{paragraph*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.7}本章小结}{29}{section.3.7}\protected@file@percent }
\abx@aux@cite{0}{speech_gesture_generation}
\abx@aux@segm{0}{0}{speech_gesture_generation}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\abx@aux@cite{0}{emage}
\abx@aux@segm{0}{0}{emage}
\pp@pagectr{footnote}{4}{51}{31}
\@writefile{toc}{\contentsline {chapter}{\numberline {第 4 章}评估}{31}{chapter.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.1}评估设置}{31}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}客观评估指标与实现细节}{31}{section.4.2}\protected@file@percent }
\newlabel{sec:objective_metrics}{{4.2}{31}{客观评估指标与实现细节}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Fréchet Gesture Distance (FGD)}{31}{subsection.4.2.1}\protected@file@percent }
\newlabel{subsec:fgd}{{4.2.1}{31}{Fréchet Gesture Distance (FGD)}{subsection.4.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{评估模型结构与训练配置.}{32}{paragraph*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{骨架拓扑敏感的自编码器.}{32}{paragraph*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{指标计算流程.}{32}{paragraph*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Speech–Gesture Rhythm Correlation (SRGR)}{33}{subsection.4.2.2}\protected@file@percent }
\newlabel{subsec:srgr}{{4.2.2}{33}{Speech–Gesture Rhythm Correlation (SRGR)}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{定义与原理.}{33}{paragraph*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{计算流程.}{33}{paragraph*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Beat Alignment (BA)}{33}{subsection.4.2.3}\protected@file@percent }
\newlabel{subsec:ba}{{4.2.3}{33}{Beat Alignment (BA)}{subsection.4.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{定义与原理.}{33}{paragraph*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{计算流程.}{34}{paragraph*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}L1-based Diversity (L1DIV)}{34}{subsection.4.2.4}\protected@file@percent }
\newlabel{subsec:l1div}{{4.2.4}{34}{L1-based Diversity (L1DIV)}{subsection.4.2.4}{}}
\@writefile{toc}{\contentsline {paragraph}{定义与原理.}{34}{paragraph*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{计算流程.}{34}{paragraph*.54}\protected@file@percent }
\abx@aux@cite{0}{diffsheg}
\abx@aux@segm{0}{0}{diffsheg}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}模型对比概览}{35}{section.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces 各模型使用的输入与输出模态。$\text  {$\mathsurround \z@ \mathchar "5D8$}$：使用；$\times $：未使用；$\ast $：未显式使用说话人 ID，但为每个说话人单独训练模型。}}{35}{table.caption.55}\protected@file@percent }
\newlabel{tab:modalitycomparison}{{4.1}{35}{各模型使用的输入与输出模态。$\checkmark $：使用；$\times $：未使用；$\ast $：未显式使用说话人 ID，但为每个说话人单独训练模型。}{table.caption.55}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}用户调研}{35}{section.4.4}\protected@file@percent }
\newlabel{sec:userstudy}{{4.4}{35}{用户调研}{section.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}评估系统与实验配置}{35}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{实验材料与呈现方式.}{35}{paragraph*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{播放系统实现.}{36}{paragraph*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{实验界面与设备.}{36}{paragraph*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{实验流程与指导.}{36}{paragraph*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{实验材料与任务设计.}{37}{paragraph*.60}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces 用户研究系统界面示意图。 左、中、右位置随机分配给三种模型， 音频与面部表情完全一致，仅身体动作不同。}}{37}{figure.caption.61}\protected@file@percent }
\newlabel{fig:userstudy_app}{{4.1}{37}{用户研究系统界面示意图。 左、中、右位置随机分配给三种模型， 音频与面部表情完全一致，仅身体动作不同。}{figure.caption.61}{}}
\abx@aux@cite{0}{LatinSquareToolkit}
\abx@aux@segm{0}{0}{LatinSquareToolkit}
\@writefile{toc}{\contentsline {paragraph}{实验参与者.}{38}{paragraph*.62}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}平衡拉丁方排序设计}{38}{subsection.4.4.2}\protected@file@percent }
\newlabel{subsec:latin_square}{{4.4.2}{38}{平衡拉丁方排序设计}{subsection.4.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}结果与分析}{38}{subsection.4.4.3}\protected@file@percent }
\newlabel{subsec:user_study_result}{{4.4.3}{38}{结果与分析}{subsection.4.4.3}{}}
\@writefile{toc}{\contentsline {paragraph}{电脑用户测评结果.}{38}{paragraph*.63}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces 16 名参与者对三种模型在“真实感”、“同步性”和“多样性”三个维度的主观排名结果。}}{38}{figure.caption.64}\protected@file@percent }
\newlabel{fig:userstudy}{{4.2}{38}{16 名参与者对三种模型在“真实感”、“同步性”和“多样性”三个维度的主观排名结果。}{figure.caption.64}{}}
\@writefile{toc}{\contentsline {paragraph}{平衡拉丁方实验结果.}{38}{paragraph*.65}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces 平衡拉丁方实验版本中 8 位 VR 用户的主观排名结果， 评价维度包括“真实感”、“同步性”和“多样性”。}}{39}{figure.caption.66}\protected@file@percent }
\newlabel{fig:userstudy_latin_square}{{4.3}{39}{平衡拉丁方实验版本中 8 位 VR 用户的主观排名结果， 评价维度包括“真实感”、“同步性”和“多样性”。}{figure.caption.66}{}}
\@writefile{toc}{\contentsline {paragraph}{用户反馈分析.}{39}{paragraph*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{结果讨论.}{39}{paragraph*.68}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}定性分析}{40}{section.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces GT、CaMN、DiffSHEG 与 FaceCapGes 的动作效果对比。本模型手势响应自然，方向与头部朝向一致。}}{40}{figure.caption.69}\protected@file@percent }
\newlabel{fig3}{{4.4}{40}{GT、CaMN、DiffSHEG 与 FaceCapGes 的动作效果对比。本模型手势响应自然，方向与头部朝向一致。}{figure.caption.69}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}定量分析}{40}{section.4.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces 在 BEAT 四位说话人测试集上的定量评估结果。FaceCapGes 在所有指标上优于 CaMN，且与 DiffSHEG 表现相当。}}{40}{table.caption.70}\protected@file@percent }
\newlabel{tab1}{{4.2}{40}{在 BEAT 四位说话人测试集上的定量评估结果。FaceCapGes 在所有指标上优于 CaMN，且与 DiffSHEG 表现相当。}{table.caption.70}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}消融实验分析}{41}{section.4.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces 说话人 2 的消融实验结果。头部姿态对提升手势自然性与表达力有显著作用。}}{41}{table.caption.71}\protected@file@percent }
\newlabel{tab2}{{4.3}{41}{说话人 2 的消融实验结果。头部姿态对提升手势自然性与表达力有显著作用。}{table.caption.71}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}性能评估}{41}{section.4.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces 在 RTX 4090 上的帧级推理速度评估结果。}}{41}{table.caption.72}\protected@file@percent }
\newlabel{tab3}{{4.4}{41}{在 RTX 4090 上的帧级推理速度评估结果。}{table.caption.72}{}}
\abx@aux@cite{0}{AppleARKitTrackingGuide}
\abx@aux@segm{0}{0}{AppleARKitTrackingGuide}
\pp@pagectr{footnote}{5}{63}{43}
\@writefile{toc}{\contentsline {chapter}{\numberline {第 5 章}结论}{43}{chapter.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{参考文献}{45}{chapter*.73}\protected@file@percent }
\abx@aux@cite{0}{LatinSquareToolkit}
\abx@aux@segm{0}{0}{LatinSquareToolkit}
\abx@aux@cite{0}{diffsheg}
\abx@aux@segm{0}{0}{diffsheg}
\abx@aux@cite{0}{beatcamn}
\abx@aux@segm{0}{0}{beatcamn}
\pp@pagectr{footnote}{6}{69}{49}
\@writefile{toc}{\contentsline {chapter}{\numberline {附录 A}平衡拉丁方排序设计}{49}{appendix.A}\protected@file@percent }
\newlabel{fig:userstudy_latin_square}{{A.1}{49}{平衡拉丁方实验版本中的用户主观评分结果，共 8 位参与者，评价维度包括“真实感”、“同步性”和“多样性”。}{figure.caption.74}{}}
\newlabel{fig:userstudy_app}{{A.2}{50}{用户研究中使用的手势播放界面示意图。}{figure.caption.75}{}}
\@writefile{toc}{\contentsline {chapter}{致\quad 谢}{51}{section*.76}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{学术论文和科研成果目录}{53}{section*.78}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{个人简历}{55}{section*.82}\protected@file@percent }
\ttl@finishall
\HyPL@Entry{76<</S/r>>}
\ttl@finishall
\abx@aux@read@bbl@mdfivesum{25B2D45080AC287087F169196A7E99A1}
\abx@aux@defaultrefcontext{0}{mediapipefacemesh}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{AppleARKitTrackingGuide}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{beatcamn}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{mcneill_1992_hand}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{kendon_2004_gesture}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{gesture_and_speech_in_interaction}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{busso2007rigidheadmotion}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{rot6d}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{diffsheg}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{emage}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ARKitDocumentation}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ozel_arkit_facs_cheatsheet}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ginosar2019speech2gesture}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{kucherenko2021predictability}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{behavior_expression_animation_toolkit}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{robot_behavior_toolkit}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{gesture_generation_by_imitation}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{AMUSE2024}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{zhang2024SemanticGesticulator}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{tamingDiffgesture}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{diffstylegesture}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{DiffTED2024}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{diffusion-self-supervised2023}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{yoon2020speechgesturebert}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{alexanderson2023diffgesture}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{alexanderson2020stylegestures}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{kucherenko2021movingfastslow}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{adam2017}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{speech_gesture_generation}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{LatinSquareToolkit}{none/global//global/global/global}
\gdef \@abspage@last{78}

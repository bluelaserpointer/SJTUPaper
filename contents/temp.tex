
\section{系统设计思路}

\subsection{手势生成目标的选择}
手势生成任务可根据其对语义上下文的依赖程度与时间结构的复杂度，
大致划分为以语义理解为核心的“语义驱动型生成”，
与以韵律对齐为核心的“韵律驱动型生成”。
本文面向用户实时数字人驱动场景，在严格因果与低延迟约束下，
模型无法访问未来语音或完整文本语义，因此难以稳定生成对语义推理要求较高的形象性、隐喻性与指示性手势。
基于该约束，本文将研究重点聚焦于与语音韵律高度同步的节奏型手势生成，并将其视为在实时交互条件下具有明确表达价值且可稳定建模的随语手势形式。

在此定位下，本文提出帧级多模态级联手势生成模型 FaceCapGes，输入为实时语音特征、面部 BlendShape 权重以及头部姿态旋转参数，并在不依赖未来帧信息的条件下逐帧输出上半身骨骼姿态。模型通过多模态信号融合弥补单一语音模态在实时场景下的信息不足：面部表情提供情绪与说话强度等辅助线索，头部姿态提供节奏前瞻与空间锚定信号，从而在保持可部署实时性的同时提升生成动作的自然度、同步性与方向一致性。

综合实时数字人驱动场景的交互需求与部署约束，本文系统设计遵循以下原则：

(1) 严格因果性： 模型仅使用当前与过去的多模态输入，不访问未来帧信息；

(2) 低延迟： 支持帧级在线推理，满足实时交互的时延要求；

(3) 可实时采集模态： 输入模态需能通过常见设备实时获取，包括语音、面部参数与头部姿态；

(4) 可稳定建模： 在上述约束下优先建模节奏型手势，并将其作为核心生成目标；

\subsection{节奏型手势在随语手势中的重要性}
尽管节奏型手势通常不承载具体语义信息，%
已有研究表明，其在交流效果与听众感知层面仍具有独立的价值。%
Baars等的实验\cite{FlapThoseHands}比较了无手势、仅使用节奏型手势、以及包含了形象性、隐喻性、指示性的意义性手势的三种演讲条件，%
结果显示，相较于完全不做手势，仅使用节奏型手势即可显著提升听众对说话者自然度的主观评价，并一定程度上提升了听众对演讲内容的记忆表现。%
而包含意义性手势的演讲条件在自然度与听众的记忆保留等指标上并未显著优于节奏型手势条件。
这一发现表明，即便缺乏形象性或隐喻性的语义映射，节奏型手势仍能通过与语音韵律的同步，对交流过程产生积极影响。

从功能上看，节奏型手势主要服务于语篇结构与韵律组织，%
其作用并非传递附加语义，而是通过时间对齐、重音标记与注意力引导，%
增强语音信息的感知显著性与节奏感。%
在真实的人机交互与虚拟人系统中，
这类手势常被作为一种低语义依赖、但高度稳健的非语言表达形式加以采用。

鉴于本文面向低延迟、严格逐帧的在线驱动场景，%
系统在任一时间步均无法获取未来文本或完整语义结构，%
对语义一致性要求较高的形象性与隐喻性手势难以可靠生成。%
相比之下，节奏型手势主要依赖于当前及局部时间窗口内的语音韵律特征，%
更适合在实时条件下进行稳定建模与生成。%
因此，本文选择以节奏型手势作为主要研究对象，%
并将其视为一种在系统约束下具有明确交互价值的可行随语手势形式。

\subsection{引入头部姿态的动机与贡献}
从生成可行性的角度，现有研究普遍认为节奏型手势可在无语义理解的条件下由语音韵律直接驱动生成。
多数语音驱动手势研究证实，仅凭语音的能量、时长与音高变化即可合成自然的节奏性上肢动作\cite{ginosar2019speech2gesture,alexanderson2020stylegestures,kucherenko2021movingfastslow}。
这些研究所生成的动作在时间结构上与语音重音同步，体现了语音与手势共享的时间规划机制。

相比之下，iconic（形象性）、metaphoric（隐喻性）与deictic（指向性）手势均依赖语义或指向关系，
需要从上下文分析语义与语境，难以在严格实时的因果条件下生成。
而节奏相关特征在音频中则具有更高的可预测性。\cite{kucherenko2021predictability}
这表明，在缺乏未来语义与全局上下文的实时场景中，仅凭语音模态，模型只能稳定生成节奏层面的动作。

为突破这一限制，本文引入头部姿态模态作为补充输入信号。头部姿态能在实时因果条件下提供部分空间与时间线索：其转头与注视方向反映互动焦点，点头与抬头与语音重读共现，能够在不依赖未来语义信息的前提下，为手势生成提供弱先验约束。
这种模态扩展为实时系统提供了理论上的可行性基础，使模型能够在语音之外获得关于节奏、方向与视角的附加信息。

\subsubsection{头部姿态对手势预测的贡献}
头部动作在自然语音中常呈现出一定的时间前瞻性~\cite{esteve2017timing}：%
其启动往往早于对应韵律词的发声，%
这意味着视觉模态可能比声学信号更早反映语音节奏的变化趋势。%
这种时序特性为实时生成任务提供了潜在的预测窗口，%
使系统能够在语音节奏变化尚未显现前，就提前捕获相关的动态线索。%
因此，头部姿态在实时生成中不仅提供同步参考，也可能在时间上形成前驱信号，为手势节奏的自然启动提供时序优势。%

\subsubsection{头部姿态对空间锚定与视角一致性的贡献}
头部姿态模态为实时语音驱动的手势生成提供了关键的空间参照信号。%
其与语音韵律在时间组织上高度耦合。%
即使在无未来语义信息的条件下，头部的转向与注视变化仍能反映说话者的注意焦点与叙述方向，%
从而帮助模型在动作生成中保持空间的连贯性与方向一致性。%
这一机制使系统能够在时间与空间两个维度上同步对齐语音与动作，%
让生成的手势在视觉上更具互动感与表达意图。

在McNeill的四类手势体系中，头部姿态的引入主要强化了两类动作的生成：  

(1) 对beat手势而言，它为语音重读和节奏段落提供显式的时间协同信号，使手部与头部动作在韵律层面更加一致；  

(2) 对iconic手势而言，它在具有路径与方向特征的动作中提供空间参考，使模型能够在叙事空间中更稳定地确定动作的方位与轨迹方向。  

通过这两方面的强化，系统在保持实时性的同时获得了更自然的节奏衔接与空间表达。

与此同时，本文明确头部姿态模态的作用边界：其核心优势在于捕捉方向、焦点与时序节奏，而非手型语义或复杂形态描摹等细粒度语义特征。换言之，它主要改善手势的位置、方向与视角依附，而非手势的形状描绘或语义内容。对于依赖抽象语义或外指参照的metaphoric与deictic手势，仍需语言或上下文模态的补充。

总体而言，头部姿态为实时生成提供了介于韵律与语义之间的关键中层约束。%
其时间上的前瞻性与空间上的指向性共同帮助模型在低延迟条件下保持自然、连贯且空间协调的动作表现，%
从而在因果生成框架内有效拓展了语音驱动手势的可表达范围，并为节奏主导型动作的实时生成提供了结构的支持。

基于上述任务范围与模态设计原则，下一节将进一步给出本文系统的总体架构，并说明各模块在实时生成流程中的功能定位。


\section{单步因果LSTM预测器}
\label{sec:one_step_lstm}

为实现严格因果的实时手势生成，本章首先建立一个用于“下一帧动作预测”的基本单元：单步因果LSTM预测器。
该预测器在每个时间步利用当前可用的多模态输入特征，并结合历史动作上下文与循环状态，对下一帧动作进行估计。
在后续章节中，我们将该单步预测器以滑动窗口方式展开，从而形成对一个动作片段的自回归生成过程，并据此定义片段级别的监督损失与对抗训练目标。

\subsection{LSTM基本概念与状态传递机制}
\label{subsec:lstm_basics}

手势动作序列具有显著的时间依赖性：当前姿态不仅受当前输入模态（如语音、面部表情、头部姿态等）影响，也与过去的动作状态密切相关。
循环神经网络（Recurrent Neural Network, RNN）通过引入随时间递推的隐状态来建模序列依赖，而LSTM进一步通过门控机制缓解长序列训练中的梯度消失问题，从而更适合用于动作序列建模。

在标准的LSTM结构中，网络在每个时间步接收当前输入特征$\bm{x}_t$，并维护两类递推状态：隐藏状态$\bm{h}_t$与记忆单元状态$\bm{c}_t$。
其中，$\bm{h}_t$可视为与当前输出相关的短期表示，而$\bm{c}_t$作为更稳定的记忆轨道，用于在更长时间尺度上保留信息。
其递推过程可形式化表示为：
\begin{equation}
(\bm{h}_t, \bm{c}_t) = \mathrm{LSTM}(\bm{x}_t, \bm{h}_{t-1}, \bm{c}_{t-1})
\label{eq:lstm_step}
\end{equation}

根据隐状态传播方向的不同，LSTM主要分为单向LSTM（Unidirectional LSTM）与双向LSTM（Bidirectional LSTM）。

双向LSTM通过同时构建前向与反向递推路径，在输出时刻$t$的表示时会融合来自未来时间步的反向信息。
该结构在离线分析或全序列可见的任务中能够更充分利用上下文，从而提升预测性能；然而在实时生成任务中，未来输入在时刻$t$尚不可用，反向路径的依赖无法满足。

相比之下，单向LSTM沿时间正向递推，其状态更新仅依赖于过去与当前输入，从结构上满足因果约束。
对于下一帧动作生成问题，UniLSTM能够自然地被解释为一个逐步更新的预测器：在每个时间步基于当前可观测输入与历史状态输出下一帧动作估计，并将生成结果反馈至下一步，从而形成自回归（autoregressive）的实时生成流程。
此外，单向递推的状态传递机制也使得模型能够在有限的输入上下文之外保留更长程的动态信息，为后续滑动窗口展开提供了必要的记忆能力。

基于以上原因，本文采用单向LSTM作为动作生成的时序建模骨干网络，以满足严格因果的实时生成需求。
在后续的滑动窗口展开策略中（见第\ref{sec:sliding_window_rollout}节），该单步预测器将被逐帧迭代调用，从而在片段级别完成动作序列的自回归生成，并用于定义监督损失与对抗训练目标。

\subsection{双时间尺度记忆结构}
\label{subsec:dual_path_memory}

尽管单向LSTM通过递推状态$(\bm{h}_t,\bm{c}_t)$在理论上具备建模长程依赖的能力，但在自回归动作生成任务中，若仅依赖循环状态作为唯一的历史信息通道，将迫使该状态同时承担短期细节与长期规律的表征。
由于循环状态本质上是对历史信息的压缩表示，其容量有限且受LSTM的门控遗忘机制影响，短期运动细节与局部连续性约束可能难以稳定保留，从而使生成过程更易出现抖动、漂移或长期一致性下降等现象。
因此，本文在跨步循环状态之外显式提供固定长度的历史动作上下文，作为短期约束信号，以在保持长期记忆能力的同时增强逐帧预测的稳定性与可控性。

为提升逐帧生成的稳定性，本文在循环状态之外显式引入固定长度的历史动作上下文作为短期条件信息。
具体而言，设$N$为历史动作上下文长度，在预测时刻$t$的动作时，我们显式提供最近$N$帧的动作历史序列$\bm{v}_{t-N:t-1}^{B}$作为可观测输入，使模型在每一步预测中均能获得短期运动细节与局部连续性约束。
为保持因果性，该历史动作序列不包含当前待预测时刻$t$的真实动作，而采用占位符进行对齐（例如以零向量或掩码符号表示），从而形成长度为$N{+}1$的因果上下文序列。

在该设计下，模型的历史信息将通过两条互补路径传递：一方面，循环状态$(\bm{h},\bm{c})$作为长期记忆通道，用于编码超过$N$帧范围的更长程动态趋势、说话风格与运动节奏；另一方面，显式历史动作上下文作为短期精确条件，在每一步预测中直接提供最近$N$帧的局部运动信息，从而缓解状态漂移带来的不确定性，并提升自回归生成的鲁棒性。
本文采用“短期显式上下文 + 长期隐式状态”的双时间尺度记忆结构，以在严格因果约束下平衡表达能力与生成稳定性。

\subsection{窗口内预测过程的形式化表达}
\label{subsec:window_forward_formalization}

本节将第\ref{chap:model_architecture}章定义的窗口内解码结构形式化为可递推的单步因果预测器，以明确在线生成时循环状态的跨步传递方式。
在时刻$t$，模型以长度为$N{+}1$的因果上下文输入序列$\bm{Z}_t^{fuse}$作为输入（其定义见式\eqref{eq:fuse_sequence}），并分别维护躯干与上肢的LSTM隐藏状态与记忆单元状态：
$(\bm{h}_{t-1}^{T}, \bm{c}_{t-1}^{T})$与$(\bm{h}_{t-1}^{U}, \bm{c}_{t-1}^{U})$。

在在线运行时，我们将跨步传递的状态作为LSTM解码器的初始状态，从而得到窗口内输出序列并更新状态：
\begin{align}
\bm{O}_t^{T}, (\bm{h}_{t}^{T}, \bm{c}_{t}^{T}) &= \mathrm{LSTM}_{T}(\bm{Z}_t^{fuse}, \bm{h}_{t-1}^{T}, \bm{c}_{t-1}^{T}), \\
\bm{O}_t^{U}, (\bm{h}_{t}^{U}, \bm{c}_{t}^{U}) &= \mathrm{LSTM}_{U}(\bm{Z}_t^{fuse}, \bm{h}_{t-1}^{U}, \bm{c}_{t-1}^{U})
\label{eq:lstm_state_forward}
\end{align}

由于本文在时刻$t$的目标是预测当前帧动作，我们使用窗口末端输出作为当前帧潜在表征，并通过MLP解码得到$\hat{\bm{v}}_{t}^{T}$与$\hat{\bm{v}}_{t}^{U}$，最终拼接为$\hat{\bm{v}}_{t}^{B}$。
该过程已在第\ref{subsec:output_modality_decoding}节给出，此处不再赘述。

因此，可以将单步因果预测器抽象为如下递推形式：
\begin{equation}
\hat{\bm{v}}_{t}^{B},\ (\bm{h}_{t}, \bm{c}_{t})
= f_{\theta}(\bm{Z}_t^{fuse},\ \bm{h}_{t-1},\ \bm{c}_{t-1}),
\label{eq:one_step_predictor_state}
\end{equation}
其中$(\bm{h}_t,\bm{c}_t)$表示躯干、上肢LSTM状态的集合。
在第\ref{sec:sliding_window_rollout}节中，我们将进一步描述该单步预测器如何随时间滑动展开，从而在片段尺度上生成长度为$M$的动作序列，并用于定义监督损失与对抗训练目标。

\section{训练片段切割}
\label{sec:segment_construction}

本工作沿用CaMN采用的训练样本构造方式\cite{beatcamn}，将长序列动作数据切割为固定长度的短片段作为训练样本。

\subsection{固定长度片段定义}
\label{subsec:fixed_length_segment}

我们从长序列中截取长度为$L$的连续片段作为训练样本，其中片段长度由历史上下文长度$N$与片段内生成步数$M$共同决定：
\begin{equation}
L = N + M
\label{eq:segment_length}
\end{equation}
在本文设定中，沿用CaMN的片段长度配置取$L=34$帧，同时选取历史上下文长度$N=16$帧，因此对应的片段内自回归生成步数为$M=18$帧。

对于第$k$个训练片段，其时间范围为$[s_k, s_k + L - 1]$，片段内的动作与多模态输入分别表示为：
\begin{align}
\bm{V}_k^B &= (\bm{v}_{s_k}^B, \bm{v}_{s_k+1}^B, \ldots, \bm{v}_{s_k+L-1}^B), \\
\bm{Z}_k &= \left(\{ \bm{z}_{s_k:t}^A \}_{t=s_k}^{s_k+L-1},\ \{ \bm{z}_{s_k:t}^F \}_{t=s_k}^{s_k+L-1},\ \{ \bm{z}_{s_k:t}^H \}_{t=s_k}^{s_k+L-1}\right)
\label{eq:segment_definition}
\end{align}
其中$\bm{V}_k^B$将进一步划分为两部分：前$N$帧作为片段的历史上下文（亦即前置动作帧，用于缓冲与提供因果条件），后$M$帧为片段内需要逐帧生成并参与训练目标计算的部分。
该划分将于第\ref{sec:sliding_window_rollout}节中用于描述滑动窗口展开过程与片段级损失计算策略。


\subsection{重叠切割与样本覆盖}
\label{subsec:overlap_sampling}

为提高训练样本覆盖率并增强模型对不同对齐位置的鲁棒性，我们参考CaMN\cite{beatcamn}采用带重叠的滑动切割方式从长序列中提取片段。
具体而言，片段起始位置$s_k$按固定步长$\Delta$滑动：
\begin{equation}
s_k = 1 + (k-1)\Delta,
\label{eq:segment_stride}
\end{equation}
从而得到一组相互重叠的训练片段$\{\bm{V}_k^B, \bm{Z}_k\}$。
在本文实现中，沿用CaMN的设置取$\Delta=10$帧，以在样本数量与数据冗余之间取得平衡。

此外，为了片段之间的连贯性，我们在每个片段的开头加入一定长度的前置动作帧。

上一节定义了训练样本以固定长度片段组织：每个片段长度为$L=N+M$，其中前$N$帧为历史上下文，后$M$帧为需要逐帧生成的目标区间。
本节进一步描述片段内部的滑动窗口展开策略：该策略在训练与推理阶段保持一致，以单步因果预测器（第\ref{sec:one_step_lstm}节）为基本计算单元，逐帧生成长度为$M$的动作序列并拼接得到片段级输出。
在本文设定中，$L=34$，$N=16$，因此$M=18$，窗口长度为$N{+}1=17$。

在严格因果的实时生成中，模型在时刻$t$预测动作时不能访问未来输入，并且其输出需要在片段之间保持连续。
为此，我们将每个片段的前$N$帧动作视为前置动作帧，其作用是为后续生成提供短期运动上下文，并避免片段边界处出现断裂。

在片段开始时刻$s_k$，我们首先执行预热阶段：将片段的前$N$帧真实动作$\{\bm{v}_{s_k}, \ldots, \bm{v}_{s_k+N-1}\}$写入历史动作缓存$\mathcal{H}$，并同步读取对应的多模态输入特征。
本文在预热阶段不执行任何前向计算，生成阶段的初始LSTM状态由预设初始化值给出。
本文采用零初始化作为$(\bm{h}_{t-1}, \bm{c}_{t-1})$的初值。

\subsection{滑动窗口展开与逐帧自回归生成}
\label{subsec:sliding_window_rollout_process}

在预热阶段结束后，我们进入生成阶段：模型在片段内部进行$M$步滑动窗口展开，每一步生成1帧动作，并将预测结果写回历史动作缓存以供下一步使用。
设片段内生成阶段的第$m$步对应全局时间$t = s_k + N - 1 + m$（其中$m=1,2,\ldots,M$），历史动作缓存$\mathcal{H}_{t-1}$包含最近$N$帧可用动作序列：
\begin{equation}
\mathcal{H}_{t-1} = (\tilde{\bm{v}}_{t-N}^{B}, \ldots, \tilde{\bm{v}}_{t-1}^{B}),
\label{eq:history_buffer}
\end{equation}
其中$\tilde{\bm{v}}$表示当前可用的动作帧：在生成开始时它包含真实前置动作帧，在生成推进过程中则逐渐由模型预测结果覆盖。

在时间步$t$，我们构造长度为$N{+}1$的因果上下文窗口，组合当前可观测的多模态输入特征与历史动作缓存，形成融合输入序列$\bm{Z}_t^{fuse}$（其定义见式\eqref{eq:fuse_sequence}）。
其中历史动作序列部分采用$(\tilde{\bm{v}}_{t-N}^{B}, \ldots, \tilde{\bm{v}}_{t-1}^{B}, \mathbf{0})$进行对齐，末帧使用占位符以保证严格因果性。

随后，单步因果预测器以$\bm{Z}_t^{fuse}$与跨步LSTM状态作为输入，输出当前帧动作预测$\hat{\bm{v}}_{t}^{B}$并更新状态（窗口内形式化表达见第\ref{subsec:window_forward_formalization}节）。
生成结果$\hat{\bm{v}}_{t}^{B}$会被写回历史动作缓存，从而更新$\mathcal{H}_t$并用于下一时间步预测：
\begin{equation}
\mathcal{H}_{t} = (\tilde{\bm{v}}_{t-N+1}^{B}, \ldots, \tilde{\bm{v}}_{t-1}^{B}, \hat{\bm{v}}_{t}^{B})
\label{eq:history_update}
\end{equation}
通过上述逐帧自回归展开，我们得到片段内生成区间的预测序列：
\begin{equation}
\hat{\bm{V}}_k^{gen} = (\hat{\bm{v}}_{s_k+N}^{B},\ \hat{\bm{v}}_{s_k+N+1}^{B},\ \ldots,\ \hat{\bm{v}}_{s_k+L-1}^{B}),
\label{eq:generated_segment}
\end{equation}
其长度为$M$。

\subsection{拼接生成序列与片段级输出}
\label{subsec:segment_level_output}

由于滑动窗口展开在每一步仅生成1帧动作，片段级输出通过对$M$步预测结果进行时间维拼接获得。
片段级生成结果$\hat{\bm{V}}_k^{gen}$与真实动作片段$\bm{V}_k^B$在时间上对齐，其中前$N$帧为可观测上下文，后$M$帧为模型生成输出。
因此，后续训练目标的定义将以$\hat{\bm{V}}_k^{gen}$为核心对象，并与真实片段中对应的生成区间进行比较。

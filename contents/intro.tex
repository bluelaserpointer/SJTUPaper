% !TEX root = ../main.tex

\chapter{引言}

\section{研究背景和意义}

近年来，随着元宇宙、虚拟社交与直播等领域的相关技术日趋成熟，用户已能够使用任意外观的虚拟人作为交互载体，在虚拟空间中与异地用户进行交流。虚拟人3D模型的姿态由其内部骨架关节的旋转参数（如欧拉角、四元数等）定义，最终通过蒙皮渲染技术完成可视化。得益于自动骨骼绑定技术，骨骼动画的生成可消除不同3D模型间的骨架拓扑差异，实现跨模型复用。

在虚拟人交互中，穿戴式动作捕捉设备是实时驱动手势的传统方案，贴合肢体的标记点可将肢体运动实时转换为相同的骨骼动画，提供直观、准确的操控。尽管其精度较高，但对于大多数用户而言，此类设备存在功能用途单一、硬件成本昂贵、便携性差等问题，限制了使用频率。因此，在当前的虚拟人交互应用中，仅少数专业用户会使用此类设备，而多数用户在设备限制下无法简单控制虚拟人肢体，导致了两种用户体验之间的不一致。

针对普通用户对低门槛虚拟人交互的需求，基于相机的动作捕捉技术\cite{mediapipefacemesh,AppleARKitTrackingGuide}成为主流替代方案。该技术无需额外硬件，仅通过手机或电脑的内置相机即可实时捕捉用户动作，用于转化为骨骼动画。然而，该方案仍存在三种局限：一是这种方法要求用户面向相机做出手势，过程中难以同步操作键盘、鼠标，造成操作冲突；二是手势活动范围受相机视野限制，在自然使用距离通过手机或电脑的内置相机拍摄用户，将严重限制手势的捕捉范围；三是持续的手势动作会产生体力消耗，在直播等长时间使用场景中，用户疲劳问题将变得显著。

基于上述问题，本文提出一种面向真实用户交互的需求：在无需用户实际做出手势的前提下，仅利用实时语音、面部捕捉与头部姿态信号，在线生成与语音匹配的上半身手势骨骼动画，从而降低使用门槛并缓解操作冲突与疲劳问题。

然而，现有研究尚难以直接满足该需求。
其一，许多手势生成方法依赖完整的语音或文本输入，而真实交互中的语音通常以流式方式逐步输入；若等待未来输入以获得更完整语义，将不可避免地引入端到端延迟。
其二，尽管头部姿态与手势节奏及空间指向存在明确关联，且可由常规相机实时捕捉，但将头部姿态作为输入特征以提升在线生成自然度的研究仍相对不足。

为此，本文将提出一种新颖的实时手势生成模型。该模型以帧为单位，输入语音、面部表情与头部姿态数据，并逐帧输出对应的骨骼动画。此外，本文在实时手势生成中，尝试将头部姿态作为一种新的模态引入，利用其与自然手势节奏与朝向的高度相关性，结合语音和面部信息共同提升生成动作的自然度。本文采用级联多模态架构与自回归训练来融合这些模态，以学习其联合表征，从而在严格的实时约束下增强手势的表现力。

因此，下面将从语音驱动手势生成的发展脉络出发，总结现有方法，并指出在线实时手势生成仍待解决的问题。

\section{国内外研究现状}

\subsection{手势分类体系与理论框架}
早期语言学与手势研究对人类交流手势建立了较为系统的分类框架。
一般而言，手势是与语音共同出现的身体动作信号，可承担语义补充、情感表达与互动调节等多重功能。
这类动作通常具有明确的交际意图，从而区别于维持平衡、行走等以完成物理任务为主的功能性动作\cite{kendon_2004_gesture}。
在 Kendon 等人的理论框架下，手势与语言并非两个相互独立的系统，而是被视为共享认知与表达过程的协同产物。

需要说明的是，本文在广义层面使用“手势”一词时，其运动形式不局限于手部动作，
也可扩展至头部运动与躯干姿态等与表达相关的上半身动作。

\subsubsection{Kendon连续体}
Kendon 连续体\cite{kendon_2004_gesture,mcneill_1992_hand}
从语言化/符号化程度的连续变化角度，将交际性手势置于以下谱系中：

随语手势（gesticulation） %

$\rightarrow$ 语言样手势（language-like gestures） %

$\rightarrow$ 拟态/哑剧式动作（pantomime） %

$\rightarrow$ 约定俗成的象征手势（emblems） %

$\rightarrow$ 手语（sign language）%

此连续体中，越靠左，通常更依赖当前的言语与语境、形式更即兴；%
越靠右，越接近离散的符号系统，规约化程度高，意义更稳定，可在缺少口语的情况下独立传达。%

当前人机交互、虚拟人/数字人驱动等方向的手势生成，%
多数工作聚焦于Kendon连续体最左侧的随语手势，%
即说话过程中自然出现、与语音节奏与语义强关联的上肢动作。
其含义往往依赖当前的口语与语境，脱离它们时通常难以传达清晰含义。%

相对而言，连续体右侧的手势更接近文化中约定俗成的符号，可以脱离口语独立传达含义。%
例如，表达称赞的拍手动作，或表示"请保持安静"的嘴前竖起食指的动作。
这些被视为象征手势，通常不在手势生成领域的研究对象中。

因此，本文将研究范围限定为随语手势的学习与生成。

\subsubsection{随语手势的分类}
McNeill\cite{mcneill_1992_hand}将随语手势进一步划分为四种基本类型：%

（1）形象性手势（Iconic gestures）：
以具象方式描绘事物的外形、空间路径或动作特征。
例如，用手势勾勒一个物体的轮廓，或划出一道线表示移动的轨迹。此类手势与语言内容直接对应，表达具体语义。

（2）隐喻性手势（Metaphoric gestures）：
表达抽象概念或思维结构的手势，%
比如用双手做出捧起一个物体放到一边的动作，表示“先把这个话题放一边”。%
这种手势并不描绘实体，而是以具象化的方式呈现抽象语义。

（3）指示性手势（Deictic gestures）：
指向空间中的对象、人物或方向，常用于对话焦点的指明与注意引导。

（4）节奏型手势（Beat gestures）：
与语音重音、韵律或节奏同步的节奏性动作，通常不承载具体语义，但可用于强调语音节奏，引起听众对说话内容的注意。

这四类手势构成了随语手势在语义与语篇功能上的主要维度，并在自然交流中常以复合形式出现。%
在手势生成任务中，研究通常将其视为不同的可生成目标：
其中节奏型手势由于与语音韵律高度同步、对齐与建模相对容易，长期以来在数据驱动方法中更常被优先刻画；%
而形象性与隐喻性等语义相关手势则对文本的语义推理有更高要求，因而是更具挑战性的方向。%

鉴于本文以低延迟在线驱动为目标，本文优先建模与韵律强耦合的节奏型手势；语义一致的形象性、隐喻性手势留作后续工作。

\subsubsection{头部手势的分类}
除手部动作外，头部动作同样是手势的重要组成部分。%
头部的点动与摆动在时间结构上常与手势及语音节奏保持同步\cite{gesture_and_speech_in_interaction}，%
在语用功能上既能辅助语音韵律的组织，也能表达态度与指向信息。%

在不同研究中\cite{hadar_1989_headmovement,kendon_2004_gesture,mcneill_1992_hand}，头部动作被从多个维度加以分析，%
其主要功能可归纳为以下几方面：%

（1）韵律相关（prosodic）：
动作反映语音重音与句法节奏的对应关系；%
 
（2）语义或态度相关（semantic/attitudinal）：
动作表达说话者的情绪倾向与交际意图；%

（3）指向相关（deictic）：
动作通过转头或注视方向建立叙事空间的参照。

此外，研究表明头部动作的启动时间往往早于发声\cite{esteve2017timing}。
具体而言，头部动作存在启动与加速过程，若其峰值需与重读音节的时间对齐，则动作必须提前起势。%
因此，头部动作可能对即将到来的语音韵律具有前瞻性。%

这一特征揭示了头部动作与语音之间的时序关系，%
说明视觉模态中的运动信号有时可先于声学事件出现。%
本文研究也因此关注头部动作，并将其纳入输入模态。

基于上述对随语手势的界定，研究者开始尝试构建能够自动生成此类动作的系统。

\subsection{规则驱动阶段}

早期的手势生成系统主要依赖语言学规则与专家知识构建\cite{behavior_expression_animation_toolkit,robot_behavior_toolkit,gesture_generation_by_imitation,gesture_and_speech_in_interaction}。
这类方法通过语义分类或韵律规则将语音片段映射为预定义的手势模板（如指示、肯定、节奏性动作），并以有限的动作库组合出手势序列。
它们可在虚拟代理或机器人中实现基于语音的同步动作。
然而，手势词典与语法规则的人工设计成本较高，难以覆盖自然语音中的多样变化，导致生成结果缺乏自然性与个体差异。

\subsection{数据驱动阶段}

随着大规模语音与动作配对数据的出现，研究者开始采用统计学习和深度神经网络模型学习语音与手势的映射关系。
在此阶段，语音通常作为唯一输入模态，模型通过长短期记忆网络（Long Short-Term Memory, LSTM）、多层感知机（Multilayer Perceptron, MLP）等结构预测连续手势序列。

为解决语音与手势间的多对多映射问题，研究者引入了向量量化变分自编码器（Vector Quantized Variational AutoEncoder，VQ-VAE）\cite{emage,zhang2024SemanticGesticulator,wan-etal-2025-finegrained-spatiotemporal}与扩散模型\cite{tamingDiffgesture,diffsheg,diffstylegesture,DiffTED2024,diffusion-self-supervised2023}，
在保持自然性的同时提升了生成多样性与表现力。

尽管上述深度生成模型在客观指标与视觉效果上优于传统模型，但通常依赖完整语句级上下文。
在用户实时语音下的流式逐字输入场景中，为获取未来上下文以进行语义判别与韵律对齐，需引入缓冲机制，
因此即使推理较快的模型\cite{diffsheg}，整体延迟也因上下文缓冲造成端到端的显著延迟。

\subsection{多模态扩展阶段}

为进一步提升动作表现力与语音理解能力，部分研究引入视觉模态或语言语义特征。
例如，CaMN\cite{beatcamn}在语音输入的基础上融合面部捕捉信息以增强表现；
EMAGE\cite{emage}与DiffSHEG\cite{diffsheg}同时生成手势与面部动作；
DiffTED\cite{DiffTED2024}实现了端到端的视频合成。

这些方法在生成质量上取得了显著进展，但其多数仍依赖整句级输入与离线生成设定，为后续在线实时部署带来了新的挑战。

\subsection{手势生成方法的总结}

现有研究中，大量方法默认采用离线生成设定，即假设可访问完整语句级语音或文本上下文。
这有利于模型获得更稳定的语义意图、能够在生成时进行全局时序安排，生成更连贯、语义一致性更好的动作序列。
此外，在面向 AI 虚拟形象的对话系统或内容合成任务中，
由于系统通常可以在AI开始发言前获得完整文本或语音，
生成过程也不必严格满足实时性约束，
因此，离线手势生成能够以较低的工程成本为 AI 虚拟角色提供较高质量的动作表现。

相比之下，面向真实用户交互的在线实时场景中，
系统只能获得流式语音输入并需逐帧输出动作，
无法直接沿用依赖完整上下文的离线假设。
我们在表~\ref{tab:offline_online_comparison}中，
整理了两个任务的目标、可用条件与输入模态的差异。

\begin{table}[h]
\bicaption{两种虚拟人手势生成任务目标的设定差异}{Setting Differences Between Two Virtual-Human Gesture Generation Objectives}
\centering
\label{tab:offline_online_comparison}
\begin{tabular}{@{}p{3cm}p{5.5cm}p{5.5cm}@{}}
\toprule
对比维度 & AI 虚拟形象生成 & 用户虚拟人实时生成 \\ 
\midrule
输入信息 & 完整句级语音或文本（可使用未来信息） & 实时语音流，仅使用过去与当前帧 \\ 
输出目标 & 整句手势序列（离线生成） & 连续流式手势（逐帧生成） \\ 
延迟影响 & 较低 & 较高，对用户交互体验影响大 \\ 
应用场景 & AI虚拟人、离线动画、内容合成 & 虚拟世界交互、视频会议、虚拟直播 \\ 
\midrule
语音模态 & 作为输入或由文本生成 & 作为实时输入特征 \\ 
手部手势 & 生成目标（输出） & 生成目标（输出） \\ 
面部表情 & 通常为生成目标（输出） & 可通过设备实时采集 \\ 
头部姿态 & 通常为生成目标（输出） & 可通过设备实时采集 \\ 
\bottomrule
\end{tabular}
\end{table}

由于面向用户交互的在线实时手势生成中，
用户的语音有逐字输入的特点，
系统需根据当前输入流即时生成同步手势，
不能查看未来信息，同时无法立即获得当前的语义。
这意味着本文需要设计一个新的方法，让模型能够在在线实时的输入流中生成当前的身体姿态。

此外，在此目标下，头部姿态不再是生成目标，而是可实时采集的输入特征，
但目前还没有头部姿态作为输入特征的充分讨论。
本文认为，引入头部姿态将对在线实时手势生成有重要贡献，原因如下：

\paragraph{时间前瞻性}
之前的研究表明，头部动作在自然语音中常呈现出一定的时间前瞻性~\cite{esteve2017timing}：%
其启动往往早于对应韵律词的发声，%
这意味着视觉模态可能比声学信号更早反映语音节奏的变化趋势。%
这种时序特性为实时生成任务提供了潜在的预测窗口，%
使系统能够在语音节奏变化尚未显现前，提前捕获相关的动态线索。%
因此，头部姿态在实时生成中不仅提供同步参考，也可能在时间上形成前驱信号，为手势节奏的自然启动提供时序优势。%

\paragraph{反映互动焦点}
头部姿态模态为实时语音驱动的手势生成提供了空间参考信号，%
即使在无语义信息的条件下，头部的转向与注视变化仍能反映说话者的注意焦点与手势朝向，%
从而帮助模型在动作生成中保持方向一致性。%
这一机制使用户在沉浸式虚拟环境中，更容易将虚拟人手势对齐叙事对象，%
让生成的手势在视觉上更具互动感与表达意图。

总体而言，头部姿态为实时生成提供了介于韵律与语义之间的关键中层约束。%
其时间上的前瞻性与空间上的指向性共同帮助模型在低延迟条件下保持自然、连贯且空间协调的动作表现，%
从而在因果生成框架内有效拓展了语音驱动手势的可表达范围，并为节奏型手势的实时生成提供了支持。

\section{本文研究目标与研究内容}

本文旨在面向实时数字人交互场景，研究一种可部署的在线随语手势生成方法。
与离线生成任务不同，实时交互系统要求生成过程满足严格因果约束，
即模型在任意时刻仅可利用当前及历史可观测信号进行推理，而无法依赖未来语音。
同时，系统还需具备低延迟的性能要求，
以支持逐帧驱动虚拟人并保持自然的随语手势表达效果。

在上述在线实时约束下，生成的随语手势不仅需要在形式上可行，
还需在多个质量维度上满足实际交互需求，具体包括：

（1）自然度与运动学合理性：生成动作在速度、加速度、关节角度范围与时序连续性等方面应符合人体运动规律，并在整体观感上保持自然流畅，避免高频抖动与突变等不连续现象。

（2）语音—动作同步性：生成动作的节奏变化需与语音韵律（如重音、停顿、能量变化）在时间轴上保持对齐，尤其体现在强调、停顿等处的动作起止与峰值对齐。

（3）多样性：在不同输入条件（语音韵律/说话风格）下，生成结果应具备足够的变化性，避免动作模板化。

（4）语义相关性与表达一致性：生成动作应与语音的语义内容、情感倾向及交互意图保持一致。

（5）实时性：模型推理延迟需满足实时交互要求。

为满足上述多重约束，本文提出 FaceCapGes：
一种仅依赖可在线采集信号的帧级多模态随语手势生成框架。
该框架以语音、面部表情与头部姿态为输入，
在严格因果条件下逐帧生成上半身3D骨骼动作，
使用户无需真实做出手势即可驱动虚拟形象产生自然的随语手势。

围绕上述目标，本文的研究内容汇总如下：

（1）提出面向实时交互的在线随语手势生成任务定义与系统框架，构建从多模态信号采集、流式推理到虚拟人驱动渲染的端到端流程，并实现可部署的实时数字人驱动系统。

（2）设计基于语音、面部表情与头部姿态的在线多模态动作生成结构，引入适用于实时场景的头部姿态特征编码方法，并结合 CaMN 级联解码策略实现多模态融合建模。

（3）提出满足严格因果约束的自回归训练策略，通过片段切割与滑动窗口展开实现帧级流式学习，并结合单向时序解码器与历史动作缓冲机制提升生成动作的连续性与平滑性。

（4）构建统一的数据处理、推理与渲染评估平台，开展用户主观实验、客观指标测量与实时性能测试，并与代表性方法进行对比评估，以验证本文方法的有效性与性能。

\section{论文组织架构}
本文章节安排如下：

第一章陈述在线实时数字人驱动场景下，语音驱动手势生成的研究背景与意义，总结国内外研究现状并对比离线生成与在线生成任务的差异，在此基础上明确本文的研究目标与主要贡献；

第二章围绕在线实时手势生成系统展开，先进行需求分析，再说明多模态数据来源与参数化表示，并给出端到端系统框架与模块划分；

第三章介绍本文多模态级联手势生成模型 FaceCapGes，包括头部姿态模态的引入方式、编码器结构设计以及身体姿态的层次化解码过程；

第四章介绍本文模型的训练方法，提出滑动窗口自回归训练与推理一致性策略，给出片段切割、窗口展开、监督损失与对抗训练目标的定义；

第五章介绍本文模型的主观与客观评估，并从定性分析、消融实验与性能测试等角度验证本文方法在生成质量与实时性方面的优势；

第六章总结全文工作并讨论未来研究方向。
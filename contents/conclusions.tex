% !TEX root = ../main.tex

\chapter{结论}

\section{本文工作总结}

本文提出了 FaceCapGes，一种基于 CaMN 框架的帧级实时语音驱动手势生成模型。与依赖完整时间上下文或未来信息的离线方法不同，FaceCapGes 能够仅利用实时音频信号、面部 blendshape 权重以及头部姿态信息，在无动作捕捉设备的条件下驱动虚拟角色生成自然、连贯的手势动作。

在模型设计上，本文融合了 LSTM、MLP 与对抗学习机制，构建了级联式网络结构，并采用滑动窗口的自回归训练策略，从而在保证生成质量的同时实现低延迟的在线推理。本文首次将头部姿态作为终端输入模态系统性地引入实时手势生成任务，有效提升了生成手势在节奏协调性与整体自然度方面的表现。

综合客观评估与主观用户研究结果表明，FaceCapGes 在生成质量上显著优于 CaMN 等基线方法，并在保持实时交互能力的前提下，在多项指标上达到与主流离线方法相当的水平。此外，模型采用模块化设计，能够部署于兼容 ARKit 的轻量级设备之上，验证了其在实际交互场景中的可行性与应用潜力。


\section{未来工作展望}

\subsection{高层语义信息与系统扩展}

当前模型主要关注语音声学特征与运动感知模态对手势生成的影响，尚未显式引入语言层面的语义理解与表达意图建模。未来可结合实时语音识别与增量式语义解析技术，引入语篇结构、强调意图或对话功能等高层语义信息，以丰富手势在交互场景中的表达能力。在不破坏实时性的前提下，探索对延迟且可修正语义假设的鲁棒利用方式，将有助于提升生成手势在语义层面的准确性与一致性。

此外，现有系统在实现层面仍依赖于 ARKit 提供的面部与头部捕捉接口。未来研究可进一步扩展对通用 RGB 摄像头及非 iOS 平台的支持，通过构建跨平台的面部与姿态估计模块，降低硬件与平台依赖性，从而提升系统的可部署性与适用范围。

\subsection{面向未来趋势的预测性训练目标}

从建模目标的角度来看，当前 FaceCapGes 的训练过程主要以当前时间步手势姿态的重建误差为优化目标，即在给定历史与当前多模态输入的条件下，监督模型对当前手势的预测精度。然而，该学习目标并未对未来时间段内手势节奏与结构变化施加显式约束，使模型对历史信息的利用更多服务于当前帧生成，而非对即将发生的动作变化进行前瞻性建模。

未来的研究可在现有框架基础上，引入针对手势未来趋势的预测性监督信号，尤其是充分挖掘头部与面部动态中所蕴含的准备性线索。与直接预测未来具体手势姿态不同，该方向更侧重于对抽象化时序属性的建模，例如未来短时间窗口内的手势起始概率、运动能量变化或强调强度等。这类趋势性变量具有时间平滑、语义明确且可提前出现的特点，适合作为实时系统中的前瞻性约束。

通过在训练阶段同时优化当前手势生成与未来趋势预测两个目标，模型有望学习到更具时间结构性的中间表示，从而在不引入额外模态或显著增加系统延迟的前提下，实现对手势节奏的提前准备与更稳定的时序对齐。


\section{本章小结}

本章对本文提出的实时手势生成方法 FaceCapGes 进行了总结，回顾了模型在结构设计、多模态融合以及实时推理方面的主要贡献。通过在无需动作捕捉设备的条件下实现高质量、低延迟的手势生成，本文工作验证了基于感知模态驱动虚拟角色表达的可行性与有效性。

同时，本章从语义建模与时间结构学习两个角度，对未来可能的研究方向进行了展望。相关扩展有望在保持实时性的前提下，进一步提升生成手势在表达意图、节奏一致性与应用适应性方面的表现，为面向自然人机交互的虚拟角色系统提供更坚实的技术基础。

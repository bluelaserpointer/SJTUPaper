\chapter{基于滑动窗口的实时手势生成自回归训练}
\label{chap:training_strategy}

本章讨论在严格因果（causal）约束下，如何将第~\ref{chap:model_architecture}~章所定义的窗口内一步预测模型，展开为可用于训练与推理的逐帧自回归生成过程，并据此构建片段级（segment-level）的监督与对抗训练目标。与离线生成不同，实时生成场景中无法一次性观测未来的多模态输入（如语音、面部与头部特征），因此模型必须在每个时间步仅依赖历史信息进行下一帧动作预测。本章首先分析因果性对循环神经网络结构的约束，并说明为何采用单向 LSTM 替代双向 LSTM（BiLSTM），从而保证模型在推理阶段满足严格因果性。

在此基础上，本章进一步引入滑动窗口与前置动作帧的概念，描述片段切割训练、窗口展开生成以及自回归写回历史动作缓冲的统一流程，并给出片段级损失计算与对抗训练策略。需要强调的是，第~\ref{chap:model_architecture}~章所给出的融合特征构造与窗口内一步预测（如式~\eqref{eq:fuse_per_frame} 与式~\eqref{eq:lstm_outputs_seq}）描述了单个窗口内的前向计算；而本章所提出的滑动窗口展开，则决定了模型如何在片段内部逐帧生成并形成连续输出，以及训练目标如何在片段尺度上进行定义。

\section{单步因果LSTM预测器}
\label{sec:one_step_lstm}

为实现严格因果的实时手势生成，本章首先建立一个用于“下一帧动作预测”的基本单元：单步因果LSTM预测器。
该预测器在每个时间步利用当前可用的多模态输入特征，并结合历史动作上下文与循环状态，对下一帧动作进行估计。
在后续章节中，我们将该单步预测器以滑动窗口方式展开，从而形成对一个动作片段的自回归生成过程，并据此定义片段级别的监督损失与对抗训练目标。

\subsection{LSTM基本概念与状态传递机制}
\label{subsec:lstm_basics}

手势动作序列具有显著的时间依赖性：当前姿态不仅受当前输入模态（如语音、面部表情、头部姿态等）影响，也与过去的动作状态密切相关。
循环神经网络（Recurrent Neural Network, RNN）通过引入随时间递推的隐状态来建模序列依赖，而长短期记忆网络（Long Short-Term Memory, LSTM）进一步通过门控机制缓解长序列训练中的梯度消失问题，从而更适合用于动作序列建模。

在标准的LSTM结构中，网络在每个时间步接收当前输入特征$\bm{x}_t$，并维护两类递推状态：隐藏状态$\bm{h}_t$与记忆单元状态$\bm{c}_t$。
其中，$\bm{h}_t$可视为与当前输出相关的短期表示，而$\bm{c}_t$作为更稳定的记忆轨道，用于在更长时间尺度上保留信息。
其递推过程可形式化表示为：
\begin{equation}
(\bm{h}_t, \bm{c}_t) = \mathrm{LSTM}(\bm{x}_t, \bm{h}_{t-1}, \bm{c}_{t-1}).
\label{eq:lstm_step}
\end{equation}
上述表达式为逐时间步的递推形式。实际实现中，深度学习框架通常将该递推过程以序列形式批量展开，即将一段输入序列送入LSTM，并由网络在内部迭代计算每一时刻的$(\bm{h}_t,\bm{c}_t)$。

根据隐状态传播方向的不同，LSTM主要分为单向LSTM（Unidirectional LSTM）与双向LSTM（Bidirectional LSTM）。
单向LSTM沿时间正向递推，时刻$t$的状态仅依赖于过去与当前输入，因此满足因果约束；其隐状态可写为$\bm{h}_t = f(\bm{x}_{\le t})$。
相比之下，双向LSTM同时构建正向与反向的递推过程，其输出在时刻$t$会同时依赖过去与未来的输入信息，即$\bm{h}_t = f(\bm{x}_{\le t}, \bm{x}_{\ge t})$。
该结构在离线场景下能够更充分利用上下文，但由于反向路径引入未来信息依赖，因此不满足严格因果的实时生成需求。

基于以上差异，下一节将进一步阐述本文选择单向LSTM作为动作生成骨干网络的原因，并说明在严格因果的自回归生成过程中，如何结合循环状态与显式历史上下文以提升预测稳定性。

\subsection{选择单向LSTM的因果性动机}
\label{subsec:why_unilstm}

实时手势生成要求模型在时刻$t$只能依赖于截至当前时刻可观测的信息，即仅允许使用$\{\bm{x}_\tau\}_{\tau \le t}$（以及过去生成的动作历史）来预测当前或下一帧动作。
在此严格因果（strict causality）约束下，模型不得访问未来输入$\{\bm{x}_\tau\}_{\tau > t}$，否则将导致训练阶段的信息泄露，并使推理阶段无法复现相同的条件分布。

双向LSTM（Bidirectional LSTM, BiLSTM）通过同时构建前向与反向递推路径，在输出时刻$t$的表示时会融合来自未来时间步的反向信息。
该结构在离线分析或全序列可见的任务中能够更充分利用上下文，从而提升预测性能；然而在实时生成任务中，未来输入在时刻$t$尚不可用，反向路径的依赖无法满足。
因此，若直接使用BiLSTM进行训练，会隐式假设推理时同样可访问未来输入，导致训练与推理条件不一致（train--test mismatch），并可能造成生成阶段性能明显退化或出现不稳定行为。

相比之下，单向LSTM（Unidirectional LSTM, UniLSTM）沿时间正向递推，其状态更新仅依赖于过去与当前输入，从结构上满足因果约束。
对于下一帧动作生成问题，UniLSTM能够自然地被解释为一个逐步更新的预测器：在每个时间步基于当前可观测输入与历史状态输出下一帧动作估计，并将生成结果反馈至下一步，从而形成自回归（autoregressive）的实时生成流程。
此外，单向递推的状态传递机制也使得模型能够在有限的输入上下文之外保留更长程的动态信息，为后续滑动窗口展开提供了必要的记忆能力。

基于以上原因，本文采用单向LSTM作为动作生成的时序建模骨干网络，以满足严格因果的实时生成需求。
在后续的滑动窗口展开策略中（见第\ref{sec:sliding_window_rollout}节），该单步预测器将被逐帧迭代调用，从而在片段级别完成动作序列的自回归生成，并用于定义监督损失与对抗训练目标。

\subsection{双通路记忆：循环状态与显式历史上下文}
\label{subsec:dual_path_memory}

尽管单向LSTM通过递推状态$(\bm{h}_t,\bm{c}_t)$在理论上可以保留长程历史信息，但在自回归的动作生成任务中，仅依赖循环状态往往会带来两个实际问题。
第一，状态本身是对历史的压缩表征，短期细节可能因遗忘机制而被弱化；第二，在长序列的自回归展开过程中，生成误差会逐步反馈进入模型并影响状态更新，从而导致状态漂移（state drift）与累积误差，尤其在引入序列级对抗训练时，判别器可能进一步放大这种不稳定性。
因此，若完全依赖循环状态作为唯一的历史信息通道，模型在实时生成中容易出现动作抖动、风格发散或长期一致性下降等现象。

为提升逐帧生成的稳定性，本文在循环状态之外显式引入固定长度的历史动作上下文作为短期条件信息。
具体而言，设$N$为历史动作上下文长度（在第\ref{sec:model_architecture}章中已给出定义），在预测时刻$t$的动作时，我们显式提供最近$N$帧的动作历史序列$\bm{v}_{t-N:t-1}^{B}$作为可观测输入，使模型在每一步预测中均能获得短期运动细节与局部连续性约束。
为保持因果性，该历史动作序列不包含当前待预测时刻$t$的真实动作，而采用占位符进行对齐（例如以零向量或掩码符号表示），从而形成长度为$N{+}1$的因果上下文序列。

在该设计下，模型的历史信息将通过两条互补路径传递：一方面，循环状态$(\bm{h},\bm{c})$作为长期记忆通道，用于编码超过$N$帧范围的更长程动态趋势、说话风格与运动节奏；另一方面，显式历史动作上下文作为短期精确条件，在每一步预测中直接提供最近$N$帧的局部运动信息，从而缓解状态漂移带来的不确定性，并提升自回归生成的鲁棒性。
换言之，本文采用“短期显式上下文 + 长期隐式状态”的双时间尺度记忆结构，以在严格因果约束下平衡表达能力与生成稳定性。

需要注意的是，由于相邻时间步的显式上下文存在高度重叠，采用固定长度上下文进行逐帧预测会引入一定的重复计算开销。
然而在本文设定中，上下文长度$N$较小（本工作中$N{=}16$），该开销在实时系统中是可接受的；同时，显式上下文的反复对齐能够有效稳定自回归展开过程，并与序列级对抗训练兼容。
下一节将进一步给出窗口内预测过程的形式化表达，说明在每个时间步如何将序列输入与跨步循环状态结合，并取序列末端输出完成下一帧动作预测。

\subsection{窗口内预测过程的形式化表达}
\label{subsec:window_forward_formalization}

本节给出单步因果预测器在时刻$t$的窗口内前向计算过程，以形式化说明本文如何在显式历史上下文与跨步循环状态的共同作用下完成下一帧动作预测。
如第\ref{sec:model_architecture}章所述，本文采用多模态融合特征$\bm{z}_t^{fuse}$作为时序解码器输入，并在每一步预测中显式提供长度为$N{+}1$的因果上下文序列：
\begin{equation}
\bm{Z}_t^{fuse} = (\bm{z}_{t-N}^{fuse}, \ldots, \bm{z}_{t}^{fuse}),
\label{eq:window_fuse_seq}
\end{equation}
其中历史动作序列仅包含$\bm{v}_{t-N:t-1}^{B}$，并在末帧使用占位符对齐长度，以满足严格因果约束。

\paragraph{序列输入与跨步状态传递}
对于躯干分支与上肢分支，本文分别维护一套单向LSTM的隐藏状态与记忆单元状态：
$(\bm{h}_{t-1}^{T}, \bm{c}_{t-1}^{T})$与$(\bm{h}_{t-1}^{U}, \bm{c}_{t-1}^{U})$。
在时刻$t$，我们将上下文序列$\bm{Z}_t^{fuse}$输入对应的LSTM解码器，并以跨步传递的状态作为初始状态：
\begin{align}
\bm{O}_t^{T}, (\bm{h}_{t}^{T}, \bm{c}_{t}^{T}) &= \mathrm{LSTM}_{T}(\bm{Z}_t^{fuse}, \bm{h}_{t-1}^{T}, \bm{c}_{t-1}^{T}), \\
\bm{O}_t^{U}, (\bm{h}_{t}^{U}, \bm{c}_{t}^{U}) &= \mathrm{LSTM}_{U}(\bm{Z}_t^{fuse}, \bm{h}_{t-1}^{U}, \bm{c}_{t-1}^{U}),
\label{eq:lstm_seq_forward}
\end{align}
其中$\bm{O}_t^{T} = (\bm{o}_{t-N}^{T},\ldots,\bm{o}_{t}^{T})$与$\bm{O}_t^{U} = (\bm{o}_{t-N}^{U},\ldots,\bm{o}_{t}^{U})$表示解码器在窗口内每个时间步的输出序列。

\paragraph{末端输出用于当前帧预测}
由于本文的目标是在时刻$t$预测当前帧动作，我们仅使用窗口末端对应的输出$\bm{o}_{t}^{T}$与$\bm{o}_{t}^{U}$作为当前帧的潜在表征：
\begin{equation}
\bm{z}_{t}^{T} = \bm{o}_{t}^{T}, \quad \bm{z}_{t}^{U} = \bm{o}_{t}^{U}.
\label{eq:last_step_output}
\end{equation}
该实现与主流深度学习框架中序列式LSTM接口一致：输入序列长度为$N{+}1$，输出序列长度同为$N{+}1$，而当前帧预测仅取最后一帧输出（即$\bm{O}_t[\mathrm{end}]$）。

\paragraph{动作解码与姿态拼接。}
随后，$\bm{z}_{t}^{T}$与$\bm{z}_{t}^{U}$分别通过独立的多层感知机（MLP）解码为旋转参数，得到当前帧的躯干与上肢动作预测：
\begin{equation}
\hat{\bm{v}}_{t}^{T} = \mathrm{MLP}_{T}(\bm{z}_{t}^{T}), \quad
\hat{\bm{v}}_{t}^{U} = \mathrm{MLP}_{U}(\bm{z}_{t}^{U}).
\label{eq:mlp_decode}
\end{equation}
最终，将两路输出拼接得到当前帧的完整上半身动作：
\begin{equation}
\hat{\bm{v}}_{t}^{B} = \hat{\bm{v}}_{t}^{T} \otimes \hat{\bm{v}}_{t}^{U}.
\label{eq:body_concat}
\end{equation}

以上过程定义了本文单步因果预测器在每个时间步的计算单元：其输入为长度$N{+}1$的因果上下文序列与跨步循环状态，其输出为当前帧动作$\hat{\bm{v}}_{t}^{B}$与更新后的循环状态$(\bm{h}_{t}, \bm{c}_{t})$。
在第\ref{sec:sliding_window_rollout}节中，我们将进一步描述该单步预测器如何随时间滑动展开，从而在片段尺度上生成长度为$M$的动作序列，并用于定义监督损失与对抗训练目标。

\section{训练片段构造：基于CaMN的固定长度切割策略}
\label{sec:segment_construction}

为在严格因果约束下训练单步预测器并实现片段级的自回归生成，本工作沿用CaMN提出的训练样本构造方式，将长序列动作数据切割为固定长度的短片段（segment）作为训练样本。
该策略具有两个优点：一方面，固定长度片段能够显式限制训练时的时间范围，从而稳定模型的时序建模与优化过程；另一方面，片段化表示便于在片段内部进行滑动窗口展开，使训练流程与实时推理阶段的逐帧生成方式保持一致。

\subsection{固定长度片段定义}
\label{subsec:fixed_length_segment}

设原始动作序列为$\{\bm{v}_t^B\}_{t=1}^{T}$，以及对应的多模态输入特征序列$\{\bm{z}_t^A, \bm{z}_t^F, \bm{z}_t^H\}_{t=1}^{T}$。
我们从长序列中截取长度为$L$的连续片段作为训练样本，其中片段长度由历史上下文长度$N$与片段内生成步数$M$共同决定：
\begin{equation}
L = N + M.
\label{eq:segment_length}
\end{equation}
在本文设定中，沿用CaMN的片段长度配置取$L=34$帧，同时选取历史上下文长度$N=16$帧，因此对应的片段内自回归生成步数为$M=18$帧。

对于第$k$个训练片段，其时间范围为$[s_k, s_k + L - 1]$，片段内的动作与多模态输入分别表示为：
\begin{align}
\bm{V}_k^B &= (\bm{v}_{s_k}^B, \bm{v}_{s_k+1}^B, \ldots, \bm{v}_{s_k+L-1}^B), \\
\bm{Z}_k &= \left(\{ \bm{z}_{s_k:t}^A \}_{t=s_k}^{s_k+L-1},\ \{ \bm{z}_{s_k:t}^F \}_{t=s_k}^{s_k+L-1},\ \{ \bm{z}_{s_k:t}^H \}_{t=s_k}^{s_k+L-1}\right).
\label{eq:segment_definition}
\end{align}
其中$\bm{V}_k^B$将进一步划分为两部分：前$N$帧作为片段的历史上下文（亦即前置动作帧，用于缓冲与提供因果条件），后$M$帧为片段内需要逐帧生成并参与训练目标计算的部分。
该划分将于第\ref{sec:sliding_window_rollout}节中用于描述滑动窗口展开过程与片段级损失计算策略。

\subsection{重叠切割与样本覆盖}
\label{subsec:overlap_sampling}

为提高训练样本覆盖率并增强模型对不同对齐位置的鲁棒性，我们采用带重叠的滑动切割方式从长序列中提取片段。
具体而言，片段起始位置$s_k$按固定步长$\Delta$滑动：
\begin{equation}
s_k = 1 + (k-1)\Delta,
\label{eq:segment_stride}
\end{equation}
从而得到一组相互重叠的训练片段$\{\bm{V}_k^B, \bm{Z}_k\}$。
在本文实现中，沿用CaMN的设置取$\Delta=10$帧，以在样本数量与数据冗余之间取得平衡。

需要强调的是，固定长度片段仅用于训练样本组织与片段级展开，并不意味着模型在推理阶段以整段方式生成输出。
相反，模型在推理与训练中均以单步预测器形式逐帧运行，并在片段内部通过滑动窗口展开形成长度为$M$的生成序列。
下一节将进一步给出片段内部的滑动窗口展开机制，并说明如何将单步预测结果拼接为片段级输出。

\section{片段内部的滑动窗口展开策略}
\label{sec:sliding_window_rollout}

上一节定义了训练样本以固定长度片段组织：每个片段长度为$L=N+M$，其中前$N$帧为历史上下文，后$M$帧为需要逐帧生成的目标区间。
本节进一步描述片段内部的滑动窗口展开（sliding-window rollout）策略：该策略在训练与推理阶段保持一致，以单步因果预测器（第\ref{sec:one_step_lstm}节）为基本计算单元，逐帧生成长度为$M$的动作序列并拼接得到片段级输出。
在本文设定中，$L=34$，$N=16$，因此$M=18$，窗口长度为$N{+}1=17$。

\subsection{前置动作帧与Warm-up阶段}
\label{subsec:warmup_prefix_frames}

在严格因果的实时生成中，模型在时刻$t$预测动作时不能访问未来输入，并且其输出需要在片段之间保持连续。
为此，我们将每个片段的前$N$帧动作视为前置动作帧（prefix motion frames），其作用是为后续生成提供短期运动上下文，并避免片段边界处出现突兀断裂。
需要强调的是，前置动作帧属于可观测条件信息而非生成目标：在训练阶段它们直接来自真实动作序列，在推理阶段则来自系统缓存的历史动作（或上一片段的生成结果）。

在片段开始时刻$s_k$，我们首先执行Warm-up阶段：将片段的前$N$帧真实动作$\{\bm{v}_{s_k}, \ldots, \bm{v}_{s_k+N-1}\}$写入历史动作缓存$\mathcal{H}$，并同步读取对应的多模态输入特征。
与常见的逐帧RNN初始化不同，本文在Warm-up阶段不执行任何前向计算，即不更新LSTM状态，仅完成历史动作上下文的缓冲准备。
该设计使得模型的生成阶段从一个明确的历史缓冲状态开始，并避免在Warm-up阶段引入不必要的计算与误差传播。

由于Warm-up阶段不执行前向计算，生成阶段的初始LSTM状态由预设初始化值给出。
本文采用零初始化作为$(\bm{h}_{t-1}, \bm{c}_{t-1})$的初值。

\subsection{滑动窗口展开与逐帧自回归生成}
\label{subsec:sliding_window_rollout_process}

在Warm-up阶段结束后，我们进入生成阶段：模型在片段内部进行$M$步滑动窗口展开，每一步生成1帧动作，并将预测结果写回历史动作缓存以供下一步使用（autoregressive feedback）。
设片段内生成阶段的第$m$步对应全局时间$t = s_k + N + m$（其中$m=0,1,\ldots,M-1$），历史动作缓存$\mathcal{H}_{t-1}$包含最近$N$帧可用动作序列：
\begin{equation}
\mathcal{H}_{t-1} = (\tilde{\bm{v}}_{t-N}^{B}, \ldots, \tilde{\bm{v}}_{t-1}^{B}),
\label{eq:history_buffer}
\end{equation}
其中$\tilde{\bm{v}}$表示当前可用的动作帧：在生成开始时它包含真实前置动作帧，在生成推进过程中则逐渐由模型预测结果覆盖。

在时间步$t$，我们构造长度为$N{+}1$的因果上下文窗口，组合当前可观测的多模态输入特征与历史动作缓存，形成融合输入序列$\bm{Z}_t^{fuse}$（定义见式(\ref{eq:window_fuse_seq})）：
\begin{equation}
\bm{Z}_t^{fuse} = (\bm{z}_{t-N}^{fuse}, \ldots, \bm{z}_{t}^{fuse}),
\end{equation}
其中历史动作序列部分采用$(\tilde{\bm{v}}_{t-N}^{B}, \ldots, \tilde{\bm{v}}_{t-1}^{B}, \mathbf{0})$进行对齐，末帧使用占位符以保证严格因果性。

随后，单步因果预测器以$\bm{Z}_t^{fuse}$与跨步LSTM状态作为输入，输出当前帧动作预测$\hat{\bm{v}}_{t}^{B}$并更新状态（窗口内形式化表达见第\ref{subsec:window_forward_formalization}节）：
\begin{equation}
\hat{\bm{v}}_{t}^{B},\ (\bm{h}_{t}, \bm{c}_{t}) = f_{\theta}(\bm{Z}_t^{fuse},\ \bm{h}_{t-1},\ \bm{c}_{t-1}).
\label{eq:one_step_predictor}
\end{equation}
生成结果$\hat{\bm{v}}_{t}^{B}$会被写回历史动作缓存，从而更新$\mathcal{H}_t$并用于下一时间步预测：
\begin{equation}
\mathcal{H}_{t} = (\tilde{\bm{v}}_{t-N+1}^{B}, \ldots, \tilde{\bm{v}}_{t-1}^{B}, \hat{\bm{v}}_{t}^{B}).
\label{eq:history_update}
\end{equation}
通过上述逐帧自回归展开，我们得到片段内生成区间的预测序列：
\begin{equation}
\hat{\bm{V}}_k^{gen} = (\hat{\bm{v}}_{s_k+N}^{B},\ \hat{\bm{v}}_{s_k+N+1}^{B},\ \ldots,\ \hat{\bm{v}}_{s_k+L-1}^{B}),
\label{eq:generated_segment}
\end{equation}
其长度为$M$，对应片段的后$M$帧。

\subsection{拼接生成序列与片段级输出}
\label{subsec:segment_level_output}

由于滑动窗口展开在每一步仅生成1帧动作，片段级输出通过对$M$步预测结果进行时间维拼接获得。
片段级生成结果$\hat{\bm{V}}_k^{gen}$与真实动作片段$\bm{V}_k^B$在时间上对齐，其中前$N$帧为可观测上下文，后$M$帧为模型生成输出。
因此，后续训练目标的定义将以$\hat{\bm{V}}_k^{gen}$为核心对象，并与真实片段中对应的生成区间进行比较。
下一节将进一步给出片段级监督损失与对抗训练目标的定义，并说明为何在损失计算与判别器输入中需要移除前置动作帧的部分。

\section{片段级训练目标：监督损失与时序平滑约束}
\label{sec:segment_losses}

在训练阶段，给定来自多模态语音动作数据集（如BEAT）的配对样本序列：
\begin{equation}
\big(\bm{z}_t^{A},\, \bm{z}_t^{F},\, \bm{z}_t^{H},\, \bm{v}_t^{B}\big),
\end{equation}
模型的学习目标是在严格因果约束下生成自然、流畅且与语音节奏相匹配的上半身动作序列。
与传统离线序列预测不同，本文采用第\ref{sec:sliding_window_rollout}节所述的滑动窗口展开策略：模型在每个片段内部自回归地逐帧生成$M$帧动作，并将其拼接为片段级生成序列。

\subsection{片段级生成序列与损失计算范围}
\label{subsec:segment_level_loss_scope}

对于第$k$个训练片段，其长度为$L=N+M$（第\ref{sec:segment_construction}节），其中前$N$帧为前置动作帧（prefix frames），后$M$帧为模型需要生成的目标区间。
根据滑动窗口展开过程（式(\ref{eq:generated_segment})），模型得到片段生成区间的预测序列：
\begin{equation}
\hat{\bm{g}}_k = 
(\hat{\bm{v}}_{s_k+N}^{B},\ \hat{\bm{v}}_{s_k+N+1}^{B},\ \ldots,\ \hat{\bm{v}}_{s_k+L-1}^{B})
\in \mathbb{R}^{M \times d},
\label{eq:gen_segment_seq}
\end{equation}
其中$d$表示动作表示的维度（例如6D旋转参数的拼接维度）。
对应的真实动作序列为：
\begin{equation}
\bm{g}_k = 
(\bm{v}_{s_k+N}^{B},\ \bm{v}_{s_k+N+1}^{B},\ \ldots,\ \bm{v}_{s_k+L-1}^{B})
\in \mathbb{R}^{M \times d}.
\label{eq:gt_segment_seq}
\end{equation}

需要强调的是，片段前$N$帧前置动作仅用于提供因果历史上下文与片段平滑过渡，其本身并非生成目标。
因此，本文的监督损失仅在片段生成区间$\{s_k+N,\ldots,s_k+L-1\}$上计算，不对前置动作帧施加重构约束。
该策略与实际推理阶段一致：前置动作帧作为已知条件用于初始化历史缓存，而模型输出仅对应后续的生成区间。

\subsection{总体优化目标}
\label{subsec:total_objective}

综合考虑空间重构精度、时序平滑性以及动作分布一致性，本文的总体优化目标定义为：
\begin{equation}
\mathcal{L}_{total} =
\lambda_r  \mathcal{L}_{rec}
+ \lambda_v \mathcal{L}_{vel}
+ \lambda_a \mathcal{L}_{acc}
+ \lambda_{adv} \mathcal{L}_{adv},
\label{eq:loss_total_seg}
\end{equation}
其中$\mathcal{L}_{rec}$衡量片段生成区间的姿态重构误差，
$\mathcal{L}_{vel}$与$\mathcal{L}_{acc}$分别约束速度与加速度的连续性，
$\mathcal{L}_{adv}$表示对抗训练损失，将在第\ref{sec:adv_training}节中进一步介绍。
该组合设计在自回归展开过程中能够有效缓解高频抖动与速度漂移问题，并提升生成序列的整体动态一致性。

\subsection{姿态重构与时序平滑损失}
\label{subsec:reconstruction_smoothness_loss}

为同时保证空间重构精度与时间连续性，我们采用基于Huber误差的重构损失形式，并分别作用于姿态、速度与加速度信号。
给定任意预测序列$\hat{\bm{x}}$及其对应的真实序列$\bm{x}$，基础误差项定义为：
\begin{equation}
\mathcal{L}_{Huber}(\bm{x}, \hat{\bm{x}})
=
\beta \cdot
\mathrm{SmoothL1}
\left(
\frac{\bm{x}}{\beta},
\frac{\hat{\bm{x}}}{\beta}
\right),
\label{eq:huber_loss}
\end{equation}
其中$\mathrm{SmoothL1}(\cdot)$表示平滑L1误差，$\beta$为平滑系数，本文中设为$0.1$。

在此基础上，片段生成区间的姿态、速度与加速度损失分别定义为：
\begin{align}
\mathcal{L}_{rec} &= \mathcal{L}_{Huber}(\bm{g}_k, \hat{\bm{g}}_k), \label{eq:rec_loss}\\
\mathcal{L}_{vel} &= \mathcal{L}_{Huber}(\bm{g}_k', \hat{\bm{g}}_k'), \label{eq:vel_loss}\\
\mathcal{L}_{acc} &= \mathcal{L}_{Huber}(\bm{g}_k'', \hat{\bm{g}}_k''), \label{eq:acc_loss}
\end{align}
其中一阶与二阶时间差分$\bm{g}_k'$、$\bm{g}_k''$定义为：
\begin{equation}
\bm{g}_{k,t}' = \bm{g}_{k,t} - \bm{g}_{k,t-1}, \quad
\bm{g}_{k,t}'' = \bm{g}_{k,t}' - \bm{g}_{k,t-1}',
\label{eq:diff_def}
\end{equation}
预测序列$\hat{\bm{g}}_k'$、$\hat{\bm{g}}_k''$同理定义。

上述多尺度重构约束在自回归预测过程中能够有效缓解高频抖动与速度漂移问题，
在保证运动学精度的同时提升生成序列的时间稳定性。
需要注意的是，这些损失均作用于片段生成区间的拼接结果$\hat{\bm{g}}_k$，而非窗口内部的中间输出；
从而使损失计算与实际代码实现保持一致，并避免对重叠窗口重复计入误差。

\subsection{对抗损失}
\label{subsec:adv_loss_overview}

为进一步提升生成动作的自然度，本文引入基于判别器的对抗训练损失$\mathcal{L}_{adv}$。
判别器以序列为输入，从整体动力学分布层面约束生成结果，使其在节奏、加速度与能量变化等统计特性上与真实表演者保持一致。
对抗训练的具体形式、判别器结构以及输入序列的掩码策略（包括移除前置动作帧）将在第\ref{sec:adv_training}节中详细说明。

\subsection{损失权重设置}
各损失项的权重系数在实验中设定为
$\lambda_r = 5\times10^{2}$，
$\lambda_v = 10^{3}$，
$\lambda_a = 10^{3}$，
$\lambda_{adv} = 10^{-1}$。

\section{对抗训练：序列级判别器与前置动作掩码}
\label{sec:adv_training}

尽管第\ref{sec:segment_losses}节的监督损失能够约束生成序列在逐帧空间误差与局部平滑性上的一致性，但仅依赖点对点重构目标往往难以完全刻画真实动作序列的整体动力学分布。
为进一步提升生成动作的自然度与分布一致性，本文引入序列级判别器（discriminator），并采用基于二元交叉熵（Binary Cross Entropy, BCE）的对抗训练策略，在片段尺度上约束生成序列与真实序列的统计特性一致。

\subsection{判别器输入：基于拼接片段的序列级判别}
\label{subsec:disc_input}

与窗口内部的中间输出不同，本文的判别器直接以片段生成区间的拼接序列为输入。
对于第$k$个片段，生成器输出的预测序列$\hat{\bm{g}}_k$及其对应的真实序列$\bm{g}_k$定义见式(\ref{eq:gen_segment_seq})与式(\ref{eq:gt_segment_seq})，二者均为长度$M$的序列。
判别器$Dis(\cdot)$接收一段动作序列，并输出其来自真实数据分布的概率：
\begin{equation}
Dis(\bm{g}) \in (0,1).
\end{equation}
通过序列级输入，判别器能够从整体动力学角度判断生成动作的真实感，从而在节奏、能量变化与运动统计特性等层面提供补充监督信号。

\paragraph{前置动作帧的掩码策略}
需要强调的是，本文在对抗训练中同样不将片段前$N$帧前置动作输入判别器。
前置动作帧属于可观测上下文条件，其内容在训练阶段为真实动作，在推理阶段为历史缓存或上一片段输出；它们并非模型需要生成的目标。
若将其与生成区间一并输入判别器（如CaMN的做法），判别器将可能利用“前置帧必然真实”这一捷径特征进行判别，从而弱化对生成区间的监督作用，并将对抗梯度错误地分配到已知上下文上。
因此，本文仅对生成区间$\hat{\bm{g}}_k$与$\bm{g}_k$进行对抗判别，使对抗目标严格作用于模型实际生成的部分，并与第\ref{sec:segment_losses}节的监督损失范围保持一致。

\subsection{基于BCE的对抗损失定义}
\label{subsec:bce_gan_loss}

判别器的训练目标是区分真实序列与生成序列，其损失定义为：
\begin{equation}
\mathcal{L}_{D} =
-\mathbb{E}_{\bm{g}_k}\big[\log Dis(\bm{g}_k)\big]
-\mathbb{E}_{\hat{\bm{g}}_k}\big[\log \big(1 - Dis(\hat{\bm{g}}_k)\big)\big].
\label{eq:disc_loss_bce}
\end{equation}
生成器则希望其输出被判别器判定为真实，从而对应的对抗损失为：
\begin{equation}
\mathcal{L}_{adv} =
-\mathbb{E}_{\hat{\bm{g}}_k}\big[\log Dis(\hat{\bm{g}}_k)\big].
\label{eq:gen_adv_loss_bce}
\end{equation}
其中$\mathbb{E}_{\bm{g}_k}$与$\mathbb{E}_{\hat{\bm{g}}_k}$分别表示对真实序列与生成序列的采样期望。
该对抗目标从分布层面鼓励生成序列在整体运动统计特性上接近真实数据，从而补充监督损失在局部误差上的约束。

\subsection{交替优化策略}
\label{subsec:alternating_optimization}

在训练过程中，本文采用交替优化（alternating optimization）方式更新生成器与判别器。
具体而言，对于每个训练批次，我们首先固定生成器参数$\theta$，最小化式(\ref{eq:disc_loss_bce})更新判别器参数；
随后固定判别器参数，最小化总体损失$\mathcal{L}_{total}$（式(\ref{eq:loss_total_seg})）更新生成器参数，其中对抗项$\mathcal{L}_{adv}$由式(\ref{eq:gen_adv_loss_bce})给出。
通过上述训练方式，判别器不断提升对真实与生成序列的区分能力，而生成器则在监督约束与分布约束的共同作用下，逐步生成更加自然且时间一致的动作序列。

\section{本章小结}
\label{sec:chapter4_summary}

本章围绕严格因果的实时手势生成任务，系统阐述了本文的滑动窗口训练与推理策略，并给出了与之配套的片段级优化目标。
首先，我们建立了单步因果预测器作为基本计算单元：采用单向LSTM以满足严格因果约束，并在每个预测步中结合跨步循环状态与显式历史动作上下文，实现“短期显式条件 + 长期隐式记忆”的双时间尺度建模，从而提升自回归生成过程的稳定性与鲁棒性。
随后，我们沿用CaMN\cite{beatcamn}的固定长度片段切割方法将长序列组织为训练样本，并在片段内部执行滑动窗口展开：通过预热阶段缓冲前置动作帧，再在生成阶段逐帧自回归预测并将输出写回历史缓存，最终拼接生成的所有动作帧得到生成序列。

在训练目标方面，本章将监督损失定义在片段生成区间的拼接输出上，采用姿态、速度与加速度的多尺度Huber约束以缓解抖动与速度漂移，并进一步引入序列级判别器以提供分布一致性的对抗监督。
与基线模型CaMN不同，本文将前置动作帧视为纯条件上下文而非生成目标，在监督损失与对抗训练中均显式移除其影响，使训练目标严格作用于模型实际生成的区间，从而与实时推理阶段的因果生成流程保持一致。